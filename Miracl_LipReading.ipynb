{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Miracl-LipReading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYS3qOTHlSMo",
        "outputId": "44a1f4c6-5a94-44e5-94ad-272a64829fb0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXloa8Snr7g0",
        "outputId": "73f89bbf-4719-4314-d105-c8eb551f2eae"
      },
      "source": [
        "!pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/1b/21ca3a7f3f597045944434f8b798d546196e5d8feebb7ac915fae3fc1ce6/mediapipe-0.8.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1MB)\n",
            "\u001b[K     |████████████████████████████████| 36.1MB 180kB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (20.3.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.36.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (56.1.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kblxG8a3_LHw"
      },
      "source": [
        "from keras import utils\n",
        "from keras.models import Sequential,model_from_yaml\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, LSTM, GRU\n",
        "from keras.layers import TimeDistributed, Conv3D,MaxPooling3D, ZeroPadding3D\n",
        "from keras.layers import Bidirectional\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from imutils import face_utils\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "import imutils\n",
        "import dlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mediapipe as mp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjo3snvCUqFj"
      },
      "source": [
        "# Dlib Shape Predictor\n",
        "\n",
        "---\n",
        "\n",
        "Loading the shape predictor that will locate the landmarks of any detected faces in an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJTjdljx_S77"
      },
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNpYhCk4xQBb"
      },
      "source": [
        "numbers = re.compile(r'(\\d+)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTn3PbdBxPq0"
      },
      "source": [
        "def numericalSort(value):\n",
        "    parts = numbers.split(value)\n",
        "    parts[1::2] = map(int, parts[1::2])\n",
        "    return parts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5-WPNCEUs_U"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Takes all the frames of a video as input and returns 20 euclidean distances for each of these frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNUzjMsAMbV"
      },
      "source": [
        "def preprocessing(video_path, frame_list):\n",
        "\n",
        "    euclid_dist = np.empty(shape=(25,40))\n",
        "    inner_count = 0\n",
        "    lips = [0, 13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270, 291, 308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415]\n",
        "    for f in frame_list:\n",
        "        frame_path = os.path.join(video_path,f)\n",
        "        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
        "          frame = cv2.imread(frame_path)        \n",
        "          # Convert the BGR image to RGB before processing.\n",
        "          results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "          # Print and draw face mesh landmarks on the image.\n",
        "          if results.multi_face_landmarks:\n",
        "              mean_x,mean_y = 0,0\n",
        "              for n in lips:\n",
        "                  x_mouth = results.multi_face_landmarks[0].landmark[n].x\n",
        "                  y_mouth = results.multi_face_landmarks[0].landmark[n].y\n",
        "\n",
        "                  shape = frame.shape \n",
        "                  relative_x = int(x_mouth * shape[1])\n",
        "                  relative_y = int(y_mouth * shape[0])\n",
        "                  mean_x = mean_x + relative_x\n",
        "                  mean_y = mean_y + relative_y\n",
        "              mean_x = mean_x/40\n",
        "              mean_y = mean_y/40\n",
        "              int_count = 0\n",
        "              for n in lips:\n",
        "                  x_mouth = results.multi_face_landmarks[0].landmark[n].x\n",
        "                  y_mouth = results.multi_face_landmarks[0].landmark[n].y\n",
        "\n",
        "                  shape = frame.shape \n",
        "                  relative_x = int(x_mouth * shape[1])\n",
        "                  relative_y = int(y_mouth * shape[0])\n",
        "                  euclid_dist[inner_count,int_count] = math.sqrt(math.pow((mean_x-relative_x),2)+math.pow((mean_y-relative_y),2))\n",
        "                  int_count += 1\n",
        "          inner_count +=1  \n",
        "\n",
        "    return euclid_dist,1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iut_n_TCUvgu"
      },
      "source": [
        "# Data Generator\n",
        "\n",
        "---\n",
        "\n",
        "Creation of X_train, X_val, X_test, y_train, y_val, y_test arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cApNV7U1AJc3"
      },
      "source": [
        "def data_generator(word, class_dict):\n",
        "    #TRAINING SET \n",
        "    first_flag,actual_count = 0,0\n",
        "    speakers=os.listdir(train_set)\n",
        "    for s in speakers:\n",
        "        repetition = os.listdir(os.path.join(os.path.join(train_set,s),word))\n",
        "        for rep in repetition:\n",
        "            video_path = os.path.join(os.path.join(os.path.join(train_set,s),word),rep)\n",
        "            frame_list=os.listdir(video_path)\n",
        "            frame_list.sort(key=numericalSort)\n",
        "            temp,bool_flag = preprocessing(video_path, frame_list)  \n",
        "            #ONLY FOR FIRST VIDEO\n",
        "            if bool_flag == 1 and first_flag == 0:\n",
        "                X_train = temp\n",
        "                first_flag = 1\n",
        "                actual_count += 1\n",
        "\n",
        "            #FOR REST OF THE VIDEOS\n",
        "            elif bool_flag == 1:\n",
        "                X_train = np.append(X_train,temp,axis=0)\n",
        "                actual_count += 1\n",
        "\n",
        "            print(\"{}/{}\".format(actual_count,700))\n",
        "\n",
        "    X_train = X_train.reshape(actual_count,25,40).astype('float32')\n",
        "    y_train = [None]*actual_count \n",
        "    for i in range(actual_count):\n",
        "        y_train[i] = class_dict[word]\n",
        "\n",
        "    #VALIDATION SET\n",
        "    first_flag,actual_count = 0,0\n",
        "    speakers=os.listdir(val_set)\n",
        "    for s in speakers:\n",
        "        repetition = os.listdir(os.path.join(os.path.join(val_set,s),word))\n",
        "        for rep in repetition:\n",
        "            video_path = os.path.join(os.path.join(os.path.join(val_set,s),word),rep)\n",
        "            frame_list = os.listdir(video_path)\n",
        "            frame_list.sort(key=numericalSort)\n",
        "\n",
        "            temp,bool_flag = preprocessing(video_path, frame_list)  \n",
        "\n",
        "            if bool_flag == 1 and first_flag == 0:\n",
        "                X_val = temp\n",
        "                first_flag = 1\n",
        "                actual_count += 1\n",
        "\n",
        "            elif bool_flag == 1:\n",
        "                X_val = np.append(X_val,temp,axis=0)\n",
        "                actual_count += 1\n",
        "\n",
        "            print(\"{}/{}\".format(actual_count,210))\n",
        "\n",
        "    X_val = X_val.reshape(actual_count,25,40).astype('float32')\n",
        "\n",
        "    y_val = [None]*actual_count \n",
        "    for i in range(actual_count):\n",
        "        y_val[i] = class_dict[word]\n",
        "\n",
        "\n",
        "\n",
        "    #TEST SET#\n",
        "    first_flag,actual_count = 0,0\n",
        "    speakers=os.listdir(test_set)\n",
        "    for s in speakers:\n",
        "        repetition = os.listdir(os.path.join(os.path.join(test_set,s),word))\n",
        "        for rep in repetition:\n",
        "            video_path = os.path.join(os.path.join(os.path.join(test_set,s),word),rep)\n",
        "            frame_list = os.listdir(video_path)\n",
        "            frame_list.sort(key=numericalSort)\n",
        "\n",
        "            temp,bool_flag = preprocessing(video_path, frame_list)  \n",
        "\n",
        "            if bool_flag == 1 and first_flag == 0:\n",
        "                X_test = temp\n",
        "                first_flag = 1\n",
        "                actual_count += 1\n",
        "\n",
        "            elif bool_flag == 1:\n",
        "                X_test = np.append(X_test,temp,axis=0)\n",
        "                actual_count += 1\n",
        "\n",
        "            print(\"{}/{}\".format(actual_count,140))\n",
        "    X_test = X_test.reshape(actual_count,25,40).astype('float32')\n",
        "\n",
        "    y_test = [None]*actual_count \n",
        "    for i in range(actual_count):\n",
        "        y_test[i] = class_dict[word]\n",
        "\n",
        "    y_train = np.asarray(y_train)\n",
        "    y_test = np.asarray(y_test)\n",
        "    y_val = np.asarray(y_val)\n",
        "\n",
        "    return X_train,y_train,X_val,y_val,X_test,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joR08x8NUyLZ"
      },
      "source": [
        "# Array Creation\n",
        "\n",
        "---\n",
        "\n",
        "Creating the train, validation and test sets for each class in the list of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylkt4S5mATg1"
      },
      "source": [
        "def create_dataset(class_dict):\n",
        "    first_flag, counter = 0,0\n",
        "    for word in class_dict.keys():\n",
        "        trainX,trainY,valX,valY,testX,testY = data_generator(word, class_dict)\n",
        "\n",
        "        if first_flag == 0:\n",
        "            X_train = trainX\n",
        "            X_test = testX\n",
        "            X_val = valX\n",
        "            y_train = trainY\n",
        "            y_test = testY\n",
        "            y_val = valY\n",
        "            first_flag = 1\n",
        "        else:\n",
        "            X_train = np.append(X_train,trainX,axis=0)\n",
        "            X_test = np.append(X_test,testX,axis=0)\n",
        "            X_val = np.append(X_val,valX,axis=0)\n",
        "            y_train = np.append(y_train,trainY,axis=0)\n",
        "            y_test = np.append(y_test,testY,axis=0)\n",
        "            y_val = np.append(y_val,valY,axis=0)\n",
        "\n",
        "        counter+=1        \n",
        "        print(\"Words processed:{}/{}\".format(counter,10))\n",
        "\n",
        "    y_train = utils.to_categorical(y_train)\n",
        "    y_test = utils.to_categorical(y_test)\n",
        "    y_val = utils.to_categorical(y_val)\n",
        "\n",
        "    return X_train,X_test,X_val,y_val,y_train,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmD0EGtRApBW"
      },
      "source": [
        "actual_class_dict = {'01':'Begin','02':'Choose','03':'Connection','04':'Navigation','05':'Next','06':'Previous','07':'Start','08':'Stop','09':'Hello','10':'Web'}\n",
        "class_dict = {'01':1,'02':2,'03':3,'04':4,'05':5,'06':6,'07':7,'08':8,'09':9,'10':10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYsQ-AhmlJCV"
      },
      "source": [
        "train_set = \"/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/train_set\"\n",
        "val_set = \"/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/val_set\"\n",
        "test_set = \"/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/test_set\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti0TuCE7Atb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3cb5c26-69cf-4188-add0-583c37a03f63"
      },
      "source": [
        "#Save new data\n",
        "X_train,X_test,X_val,y_val,y_train,y_test = create_dataset(class_dict) \n",
        "np.save('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/X_train3.npy',X_train)\n",
        "np.save('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/X_test3.npy',X_test)\n",
        "np.save('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/X_val3.npy',X_val)\n",
        "np.save('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/y_train3.npy',y_train)\n",
        "np.save('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/y_test3.npy',y_test)\n",
        "np.save('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/y_val3.npy',y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:1/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:2/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:3/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:4/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:5/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:6/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:7/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:8/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:9/10\n",
            "1/700\n",
            "2/700\n",
            "3/700\n",
            "4/700\n",
            "5/700\n",
            "6/700\n",
            "7/700\n",
            "8/700\n",
            "9/700\n",
            "10/700\n",
            "11/700\n",
            "12/700\n",
            "13/700\n",
            "14/700\n",
            "15/700\n",
            "16/700\n",
            "17/700\n",
            "18/700\n",
            "19/700\n",
            "20/700\n",
            "21/700\n",
            "22/700\n",
            "23/700\n",
            "24/700\n",
            "25/700\n",
            "26/700\n",
            "27/700\n",
            "28/700\n",
            "29/700\n",
            "30/700\n",
            "31/700\n",
            "32/700\n",
            "33/700\n",
            "34/700\n",
            "35/700\n",
            "36/700\n",
            "37/700\n",
            "38/700\n",
            "39/700\n",
            "40/700\n",
            "41/700\n",
            "42/700\n",
            "43/700\n",
            "44/700\n",
            "45/700\n",
            "46/700\n",
            "47/700\n",
            "48/700\n",
            "49/700\n",
            "50/700\n",
            "51/700\n",
            "52/700\n",
            "53/700\n",
            "54/700\n",
            "55/700\n",
            "56/700\n",
            "57/700\n",
            "58/700\n",
            "59/700\n",
            "60/700\n",
            "61/700\n",
            "62/700\n",
            "63/700\n",
            "64/700\n",
            "65/700\n",
            "66/700\n",
            "67/700\n",
            "68/700\n",
            "69/700\n",
            "70/700\n",
            "71/700\n",
            "72/700\n",
            "73/700\n",
            "74/700\n",
            "75/700\n",
            "76/700\n",
            "77/700\n",
            "78/700\n",
            "79/700\n",
            "80/700\n",
            "81/700\n",
            "82/700\n",
            "83/700\n",
            "84/700\n",
            "85/700\n",
            "86/700\n",
            "87/700\n",
            "88/700\n",
            "89/700\n",
            "90/700\n",
            "91/700\n",
            "92/700\n",
            "93/700\n",
            "94/700\n",
            "95/700\n",
            "96/700\n",
            "97/700\n",
            "98/700\n",
            "99/700\n",
            "100/700\n",
            "1/210\n",
            "2/210\n",
            "3/210\n",
            "4/210\n",
            "5/210\n",
            "6/210\n",
            "7/210\n",
            "8/210\n",
            "9/210\n",
            "10/210\n",
            "11/210\n",
            "12/210\n",
            "13/210\n",
            "14/210\n",
            "15/210\n",
            "16/210\n",
            "17/210\n",
            "18/210\n",
            "19/210\n",
            "20/210\n",
            "21/210\n",
            "22/210\n",
            "23/210\n",
            "24/210\n",
            "25/210\n",
            "26/210\n",
            "27/210\n",
            "28/210\n",
            "29/210\n",
            "30/210\n",
            "1/140\n",
            "2/140\n",
            "3/140\n",
            "4/140\n",
            "5/140\n",
            "6/140\n",
            "7/140\n",
            "8/140\n",
            "9/140\n",
            "10/140\n",
            "11/140\n",
            "12/140\n",
            "13/140\n",
            "14/140\n",
            "15/140\n",
            "16/140\n",
            "17/140\n",
            "18/140\n",
            "19/140\n",
            "20/140\n",
            "Words processed:10/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_psRQukwA7Hn"
      },
      "source": [
        "X_train = np.load('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/X_train3.npy')/2.56\n",
        "X_test = np.load('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/X_test3.npy')/2.56\n",
        "X_val = np.load('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/X_val3.npy')/2.56\n",
        "y_train = np.load('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/y_train3.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/y_test3.npy')\n",
        "y_val = np.load('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/y_val3.npy')\n",
        "\n",
        "y_train = np.delete(y_train,0,1)\n",
        "y_val = np.delete(y_val,0,1)\n",
        "y_test = np.delete(y_test,0,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug2Y7qwo1mlO",
        "outputId": "5277cd94-1531-40bf-a298-0d2cc1aa9fd4"
      },
      "source": [
        "X_train.shape,X_val.shape,y_train.shape,y_val.shape,X_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 25, 40),\n",
              " (300, 25, 40),\n",
              " (1000, 10),\n",
              " (300, 10),\n",
              " (200, 25, 40),\n",
              " (200, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpiKTRSATRSz"
      },
      "source": [
        "count=1000\n",
        "while count>0:\n",
        "  for i in range(count-1,count-101,-1):\n",
        "    flag=0\n",
        "    for j in range(25):\n",
        "      for k in range(40):\n",
        "        if (np.isinf(X_train[i][j][k])==True):\n",
        "          X_train[i]=X_train[count-1]\n",
        "          flag=1\n",
        "          break;\n",
        "      if flag==1:\n",
        "        break\n",
        "  count-=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koJS9Q6kRj6X"
      },
      "source": [
        "count=300\n",
        "while count>0:\n",
        "  for i in range(count-1,count-31,-1):\n",
        "    flag=0\n",
        "    for j in range(25):\n",
        "      for k in range(40):\n",
        "        if (np.isinf(X_val[i][j][k])==True):\n",
        "          X_val[i]=X_val[count-1]\n",
        "          flag=1\n",
        "          break;\n",
        "      if flag==1:\n",
        "        break\n",
        "  count-=30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNAPTBoKRkgi"
      },
      "source": [
        "count=200\n",
        "while count>0:\n",
        "  for i in range(count-1,count-21,-1):\n",
        "    flag=0\n",
        "    for j in range(25):\n",
        "      for k in range(40):\n",
        "        if (np.isinf(X_test[i][j][k])==True):\n",
        "          X_test[i]=X_test[count-1]\n",
        "          flag=1\n",
        "          break;\n",
        "      if flag==1:\n",
        "        break\n",
        "  count-=20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MRte39Q4B_p",
        "outputId": "28a7c948-1edd-4f06-a333-1aa28d3e1b0d"
      },
      "source": [
        "X_train.shape,X_val.shape,y_train.shape,y_val.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 25, 40),\n",
              " (300, 25, 40),\n",
              " (1000, 10),\n",
              " (300, 10),\n",
              " (200, 25, 40),\n",
              " (200, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JiVyJqjjLpU"
      },
      "source": [
        "# scalers = {}\n",
        "# for i in range(X_train.shape[1]):\n",
        "#     scalers[i] = MinMaxScaler()\n",
        "#     X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :])\n",
        "# for i in range(X_val.shape[1]):\n",
        "#     scalers[i] = MinMaxScaler()\n",
        "#     X_val[:, i, :] = scalers[i].fit_transform(X_val[:, i, :])\n",
        "# for i in range(X_test.shape[1]):\n",
        "#     scalers[i] = MinMaxScaler()\n",
        "#     X_test[:, i, :] = scalers[i].fit_transform(X_test[:, i, :])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiCHou9VUR6z"
      },
      "source": [
        "# np.isnan(X_train).any(),np.isnan(y_train).any(),np.isnan(X_test).any(),np.isnan(y_test).any(),np.isnan(X_val).any(),np.isnan(y_val).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpuNdxW7U2g2"
      },
      "source": [
        "# Model Creation and Fitting\n",
        "\n",
        "---\n",
        "\n",
        "Creating and fitting the model containing a Bidirectional LSTM layer and a Softmax function for classification of 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zqz-wT4A9qT"
      },
      "source": [
        "#BiLSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVxINOtVgKa"
      },
      "source": [
        "#Fitting the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlEsZt3jA-3f",
        "outputId": "4406e9ad-3a7d-4a6f-ca9b-0541bf1ffa9b"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = ModelCheckpoint('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history = model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=4000, batch_size=40, callbacks=[es,mc])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4000\n",
            "25/25 [==============================] - 6s 105ms/step - loss: 2.3844 - accuracy: 0.0954 - val_loss: 2.3097 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10000, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 2/4000\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 2.3460 - accuracy: 0.1149 - val_loss: 2.3067 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10000\n",
            "Epoch 3/4000\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 2.3196 - accuracy: 0.1094 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10000\n",
            "Epoch 4/4000\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 2.3271 - accuracy: 0.1021 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.10000\n",
            "Epoch 5/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3118 - accuracy: 0.0974 - val_loss: 2.3055 - val_accuracy: 0.0967\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.10000\n",
            "Epoch 6/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3163 - accuracy: 0.0905 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.10000\n",
            "Epoch 7/4000\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 2.3120 - accuracy: 0.0878 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.10000\n",
            "Epoch 8/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3065 - accuracy: 0.1037 - val_loss: 2.3041 - val_accuracy: 0.0967\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.10000\n",
            "Epoch 9/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3087 - accuracy: 0.1057 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.10000\n",
            "Epoch 10/4000\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 2.3088 - accuracy: 0.0931 - val_loss: 2.3034 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.10000 to 0.11333, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 11/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3105 - accuracy: 0.0968 - val_loss: 2.3031 - val_accuracy: 0.0933\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.11333\n",
            "Epoch 12/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3004 - accuracy: 0.1180 - val_loss: 2.3032 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.11333\n",
            "Epoch 13/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3033 - accuracy: 0.1151 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.11333\n",
            "Epoch 14/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.2994 - accuracy: 0.1220 - val_loss: 2.3034 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.11333 to 0.13333, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 15/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3061 - accuracy: 0.1067 - val_loss: 2.3025 - val_accuracy: 0.0733\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.13333\n",
            "Epoch 16/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3075 - accuracy: 0.1193 - val_loss: 2.3030 - val_accuracy: 0.0967\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.13333\n",
            "Epoch 17/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3071 - accuracy: 0.0978 - val_loss: 2.3023 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.13333\n",
            "Epoch 18/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.3011 - accuracy: 0.1297 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.13333\n",
            "Epoch 19/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.3033 - accuracy: 0.1144 - val_loss: 2.3023 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.13333\n",
            "Epoch 20/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.3090 - accuracy: 0.0765 - val_loss: 2.3024 - val_accuracy: 0.1233\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.13333\n",
            "Epoch 21/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 2.3022 - accuracy: 0.1215 - val_loss: 2.3024 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.13333\n",
            "Epoch 22/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.2995 - accuracy: 0.1347 - val_loss: 2.3018 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.13333\n",
            "Epoch 23/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.2969 - accuracy: 0.1267 - val_loss: 2.3018 - val_accuracy: 0.0833\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.13333\n",
            "Epoch 24/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.3001 - accuracy: 0.0981 - val_loss: 2.3009 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.13333\n",
            "Epoch 25/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3028 - accuracy: 0.1357 - val_loss: 2.3002 - val_accuracy: 0.1500\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.13333 to 0.15000, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 26/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3000 - accuracy: 0.1011 - val_loss: 2.2997 - val_accuracy: 0.1167\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.15000\n",
            "Epoch 27/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.3004 - accuracy: 0.1104 - val_loss: 2.3023 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.15000\n",
            "Epoch 28/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3001 - accuracy: 0.1155 - val_loss: 2.3004 - val_accuracy: 0.1000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.15000\n",
            "Epoch 29/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.2919 - accuracy: 0.1561 - val_loss: 2.2954 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.15000\n",
            "Epoch 30/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.2747 - accuracy: 0.1555 - val_loss: 2.3166 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.15000\n",
            "Epoch 31/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.3104 - accuracy: 0.1371 - val_loss: 2.3071 - val_accuracy: 0.0933\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.15000\n",
            "Epoch 32/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.2862 - accuracy: 0.1112 - val_loss: 2.2821 - val_accuracy: 0.1433\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.15000\n",
            "Epoch 33/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.2893 - accuracy: 0.1236 - val_loss: 2.2935 - val_accuracy: 0.1100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.15000\n",
            "Epoch 34/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.2654 - accuracy: 0.1373 - val_loss: 2.2631 - val_accuracy: 0.1367\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.15000\n",
            "Epoch 35/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.2399 - accuracy: 0.1652 - val_loss: 2.2840 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.15000\n",
            "Epoch 36/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.2788 - accuracy: 0.1182 - val_loss: 2.2447 - val_accuracy: 0.1167\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.15000\n",
            "Epoch 37/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.2342 - accuracy: 0.1349 - val_loss: 2.2136 - val_accuracy: 0.0767\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.15000\n",
            "Epoch 38/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.2109 - accuracy: 0.1517 - val_loss: 2.1896 - val_accuracy: 0.1400\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.15000\n",
            "Epoch 39/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.1859 - accuracy: 0.1654 - val_loss: 2.1709 - val_accuracy: 0.1833\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.15000 to 0.18333, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 40/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.1921 - accuracy: 0.1654 - val_loss: 2.1381 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.18333\n",
            "Epoch 41/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.1665 - accuracy: 0.1662 - val_loss: 2.1835 - val_accuracy: 0.1267\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.18333\n",
            "Epoch 42/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.1349 - accuracy: 0.2017 - val_loss: 2.1501 - val_accuracy: 0.1800\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.18333\n",
            "Epoch 43/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.1500 - accuracy: 0.1615 - val_loss: 2.1312 - val_accuracy: 0.1267\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.18333\n",
            "Epoch 44/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.1222 - accuracy: 0.1836 - val_loss: 2.2082 - val_accuracy: 0.1367\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.18333\n",
            "Epoch 45/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.1102 - accuracy: 0.1905 - val_loss: 2.1704 - val_accuracy: 0.1100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.18333\n",
            "Epoch 46/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.1126 - accuracy: 0.1819 - val_loss: 2.1145 - val_accuracy: 0.1700\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.18333\n",
            "Epoch 47/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.0618 - accuracy: 0.2111 - val_loss: 2.1098 - val_accuracy: 0.1467\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.18333\n",
            "Epoch 48/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.0218 - accuracy: 0.2369 - val_loss: 2.1708 - val_accuracy: 0.1400\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.18333\n",
            "Epoch 49/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.0240 - accuracy: 0.2463 - val_loss: 2.0919 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.18333\n",
            "Epoch 50/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.9759 - accuracy: 0.2650 - val_loss: 2.1032 - val_accuracy: 0.2133\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.18333 to 0.21333, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 51/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.9900 - accuracy: 0.2803 - val_loss: 2.0999 - val_accuracy: 0.1600\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.21333\n",
            "Epoch 52/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.9536 - accuracy: 0.2811 - val_loss: 2.0203 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.21333\n",
            "Epoch 53/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8635 - accuracy: 0.2867 - val_loss: 2.1553 - val_accuracy: 0.1567\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.21333\n",
            "Epoch 54/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.9309 - accuracy: 0.2748 - val_loss: 2.0219 - val_accuracy: 0.1733\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.21333\n",
            "Epoch 55/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.8763 - accuracy: 0.2899 - val_loss: 2.0207 - val_accuracy: 0.2467\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.21333 to 0.24667, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 56/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8267 - accuracy: 0.3061 - val_loss: 1.9479 - val_accuracy: 0.2367\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.24667\n",
            "Epoch 57/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7966 - accuracy: 0.3334 - val_loss: 1.9938 - val_accuracy: 0.2267\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.24667\n",
            "Epoch 58/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7963 - accuracy: 0.3093 - val_loss: 1.9746 - val_accuracy: 0.2133\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.24667\n",
            "Epoch 59/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7209 - accuracy: 0.3424 - val_loss: 1.9363 - val_accuracy: 0.2633\n",
            "\n",
            "Epoch 00059: val_accuracy improved from 0.24667 to 0.26333, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 60/4000\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.6713 - accuracy: 0.3740 - val_loss: 1.9306 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.26333 to 0.30667, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 61/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.6711 - accuracy: 0.3736 - val_loss: 1.9090 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.30667\n",
            "Epoch 62/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.6887 - accuracy: 0.3465 - val_loss: 2.1001 - val_accuracy: 0.2567\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.30667\n",
            "Epoch 63/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.6974 - accuracy: 0.3665 - val_loss: 2.0598 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.30667\n",
            "Epoch 64/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.5830 - accuracy: 0.4188 - val_loss: 2.0222 - val_accuracy: 0.2100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.30667\n",
            "Epoch 65/4000\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.5492 - accuracy: 0.4315 - val_loss: 1.9104 - val_accuracy: 0.2767\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.30667\n",
            "Epoch 66/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.5550 - accuracy: 0.4247 - val_loss: 1.9391 - val_accuracy: 0.2200\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.30667\n",
            "Epoch 67/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.4865 - accuracy: 0.4132 - val_loss: 1.9450 - val_accuracy: 0.2733\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.30667\n",
            "Epoch 68/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.4472 - accuracy: 0.4536 - val_loss: 2.0227 - val_accuracy: 0.1867\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.30667\n",
            "Epoch 69/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.4226 - accuracy: 0.4573 - val_loss: 2.0328 - val_accuracy: 0.2400\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.30667\n",
            "Epoch 70/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.3622 - accuracy: 0.4665 - val_loss: 2.0156 - val_accuracy: 0.2067\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.30667\n",
            "Epoch 71/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.4335 - accuracy: 0.4683 - val_loss: 1.9470 - val_accuracy: 0.2200\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.30667\n",
            "Epoch 72/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.4223 - accuracy: 0.4588 - val_loss: 1.9743 - val_accuracy: 0.2667\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.30667\n",
            "Epoch 73/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.3981 - accuracy: 0.4879 - val_loss: 2.1099 - val_accuracy: 0.2433\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.30667\n",
            "Epoch 74/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 1.3517 - accuracy: 0.4916 - val_loss: 2.0018 - val_accuracy: 0.2533\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.30667\n",
            "Epoch 75/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.3544 - accuracy: 0.5079 - val_loss: 2.0562 - val_accuracy: 0.2467\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.30667\n",
            "Epoch 76/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 1.3285 - accuracy: 0.4999 - val_loss: 1.9779 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.30667 to 0.32667, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 77/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 1.2771 - accuracy: 0.5471 - val_loss: 2.0039 - val_accuracy: 0.2967\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.32667\n",
            "Epoch 78/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.2491 - accuracy: 0.5223 - val_loss: 2.1088 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.32667\n",
            "Epoch 79/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.2138 - accuracy: 0.5451 - val_loss: 2.1516 - val_accuracy: 0.2933\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.32667\n",
            "Epoch 80/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 1.2761 - accuracy: 0.4979 - val_loss: 1.9918 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.32667 to 0.33333, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 81/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 1.1950 - accuracy: 0.5348 - val_loss: 2.2026 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.33333\n",
            "Epoch 82/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.1793 - accuracy: 0.5787 - val_loss: 2.0352 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.33333\n",
            "Epoch 83/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.1646 - accuracy: 0.5676 - val_loss: 2.1464 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.33333\n",
            "Epoch 84/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.1917 - accuracy: 0.5588 - val_loss: 2.2150 - val_accuracy: 0.2633\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.33333\n",
            "Epoch 85/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.1823 - accuracy: 0.5772 - val_loss: 2.2092 - val_accuracy: 0.2233\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.33333\n",
            "Epoch 86/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 1.1375 - accuracy: 0.5791 - val_loss: 2.1837 - val_accuracy: 0.2667\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.33333\n",
            "Epoch 87/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 1.1287 - accuracy: 0.6050 - val_loss: 2.1828 - val_accuracy: 0.2733\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.33333\n",
            "Epoch 88/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 1.1778 - accuracy: 0.5521 - val_loss: 2.1026 - val_accuracy: 0.2733\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.33333\n",
            "Epoch 89/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 1.1677 - accuracy: 0.5600 - val_loss: 2.1506 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.33333\n",
            "Epoch 90/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.1420 - accuracy: 0.5847 - val_loss: 2.0296 - val_accuracy: 0.2633\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.33333\n",
            "Epoch 91/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 1.1166 - accuracy: 0.5989 - val_loss: 2.1373 - val_accuracy: 0.2567\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.33333\n",
            "Epoch 92/4000\n",
            "25/25 [==============================] - 2s 66ms/step - loss: 1.1112 - accuracy: 0.6116 - val_loss: 2.1981 - val_accuracy: 0.2667\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.33333\n",
            "Epoch 93/4000\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 1.0756 - accuracy: 0.5855 - val_loss: 2.1046 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.33333\n",
            "Epoch 94/4000\n",
            "25/25 [==============================] - 2s 64ms/step - loss: 1.0746 - accuracy: 0.6013 - val_loss: 2.2177 - val_accuracy: 0.2400\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.33333\n",
            "Epoch 95/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 1.0460 - accuracy: 0.6129 - val_loss: 2.1920 - val_accuracy: 0.2533\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.33333\n",
            "Epoch 96/4000\n",
            "25/25 [==============================] - 2s 62ms/step - loss: 1.0746 - accuracy: 0.6156 - val_loss: 2.2207 - val_accuracy: 0.2967\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.33333\n",
            "Epoch 97/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 1.0810 - accuracy: 0.6115 - val_loss: 2.1012 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.33333\n",
            "Epoch 98/4000\n",
            "25/25 [==============================] - 2s 81ms/step - loss: 1.0300 - accuracy: 0.6258 - val_loss: 2.1177 - val_accuracy: 0.2733\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.33333\n",
            "Epoch 99/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 1.1137 - accuracy: 0.6108 - val_loss: 2.2583 - val_accuracy: 0.2433\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.33333\n",
            "Epoch 100/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 1.0700 - accuracy: 0.6115 - val_loss: 2.2164 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.33333\n",
            "Epoch 101/4000\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 1.2242 - accuracy: 0.5588 - val_loss: 2.2226 - val_accuracy: 0.2600\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.33333\n",
            "Epoch 102/4000\n",
            "25/25 [==============================] - 2s 71ms/step - loss: 1.0017 - accuracy: 0.6419 - val_loss: 2.2063 - val_accuracy: 0.2600\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.33333\n",
            "Epoch 103/4000\n",
            "25/25 [==============================] - 2s 75ms/step - loss: 0.9652 - accuracy: 0.6643 - val_loss: 2.2557 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.33333\n",
            "Epoch 104/4000\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 1.0206 - accuracy: 0.6443 - val_loss: 2.2340 - val_accuracy: 0.2967\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.33333\n",
            "Epoch 105/4000\n",
            "25/25 [==============================] - 2s 71ms/step - loss: 0.9342 - accuracy: 0.6609 - val_loss: 2.3312 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.33333\n",
            "Epoch 106/4000\n",
            "25/25 [==============================] - 2s 72ms/step - loss: 1.1182 - accuracy: 0.5925 - val_loss: 2.3557 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.33333\n",
            "Epoch 107/4000\n",
            "25/25 [==============================] - 2s 68ms/step - loss: 0.9296 - accuracy: 0.6604 - val_loss: 2.2877 - val_accuracy: 0.2567\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.33333\n",
            "Epoch 108/4000\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 1.0025 - accuracy: 0.6386 - val_loss: 2.2574 - val_accuracy: 0.2767\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.33333\n",
            "Epoch 109/4000\n",
            "25/25 [==============================] - 2s 71ms/step - loss: 0.9204 - accuracy: 0.6629 - val_loss: 2.2882 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.33333\n",
            "Epoch 110/4000\n",
            "25/25 [==============================] - 2s 71ms/step - loss: 0.9018 - accuracy: 0.6680 - val_loss: 2.3212 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.33333\n",
            "Epoch 111/4000\n",
            "25/25 [==============================] - 2s 66ms/step - loss: 0.8979 - accuracy: 0.6713 - val_loss: 2.3705 - val_accuracy: 0.2767\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.33333\n",
            "Epoch 112/4000\n",
            "25/25 [==============================] - 2s 72ms/step - loss: 1.0069 - accuracy: 0.6299 - val_loss: 2.2817 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.33333\n",
            "Epoch 113/4000\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.8951 - accuracy: 0.6758 - val_loss: 2.3028 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.33333\n",
            "Epoch 114/4000\n",
            "25/25 [==============================] - 2s 74ms/step - loss: 0.8585 - accuracy: 0.6660 - val_loss: 2.4832 - val_accuracy: 0.2300\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.33333\n",
            "Epoch 115/4000\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.9079 - accuracy: 0.6632 - val_loss: 2.3047 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.33333\n",
            "Epoch 116/4000\n",
            "25/25 [==============================] - 2s 66ms/step - loss: 0.8930 - accuracy: 0.6672 - val_loss: 2.3209 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.33333\n",
            "Epoch 117/4000\n",
            "25/25 [==============================] - 2s 68ms/step - loss: 0.9042 - accuracy: 0.6819 - val_loss: 2.3962 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.33333\n",
            "Epoch 118/4000\n",
            "25/25 [==============================] - 2s 72ms/step - loss: 0.8978 - accuracy: 0.6656 - val_loss: 2.4415 - val_accuracy: 0.2367\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.33333\n",
            "Epoch 119/4000\n",
            "25/25 [==============================] - 2s 74ms/step - loss: 0.8714 - accuracy: 0.6875 - val_loss: 2.4255 - val_accuracy: 0.2633\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.33333\n",
            "Epoch 120/4000\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 0.9440 - accuracy: 0.6752 - val_loss: 2.4660 - val_accuracy: 0.2533\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.33333\n",
            "Epoch 121/4000\n",
            "25/25 [==============================] - 2s 76ms/step - loss: 0.7924 - accuracy: 0.7342 - val_loss: 2.3986 - val_accuracy: 0.2400\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.33333\n",
            "Epoch 122/4000\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 0.8185 - accuracy: 0.7285 - val_loss: 2.4693 - val_accuracy: 0.2733\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.33333\n",
            "Epoch 123/4000\n",
            "25/25 [==============================] - 2s 69ms/step - loss: 0.9612 - accuracy: 0.6697 - val_loss: 2.3271 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.33333\n",
            "Epoch 124/4000\n",
            "25/25 [==============================] - 2s 62ms/step - loss: 0.8084 - accuracy: 0.7067 - val_loss: 2.5347 - val_accuracy: 0.2667\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.33333\n",
            "Epoch 125/4000\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.7918 - accuracy: 0.6901 - val_loss: 2.5272 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.33333\n",
            "Epoch 126/4000\n",
            "25/25 [==============================] - 2s 65ms/step - loss: 0.9639 - accuracy: 0.6516 - val_loss: 2.5263 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.33333\n",
            "Epoch 127/4000\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 0.8936 - accuracy: 0.6777 - val_loss: 2.4332 - val_accuracy: 0.2933\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.33333\n",
            "Epoch 128/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.8209 - accuracy: 0.7173 - val_loss: 2.4948 - val_accuracy: 0.2733\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.33333\n",
            "Epoch 129/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.7772 - accuracy: 0.7207 - val_loss: 2.4768 - val_accuracy: 0.2367\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.33333\n",
            "Epoch 130/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.7643 - accuracy: 0.7160 - val_loss: 2.4592 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.33333\n",
            "Epoch 131/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.7913 - accuracy: 0.7283 - val_loss: 2.4289 - val_accuracy: 0.2933\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.33333\n",
            "Epoch 132/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.8360 - accuracy: 0.6880 - val_loss: 2.6338 - val_accuracy: 0.2900\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.33333\n",
            "Epoch 133/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.8380 - accuracy: 0.7140 - val_loss: 2.4492 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.33333\n",
            "Epoch 134/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.7382 - accuracy: 0.7345 - val_loss: 2.5869 - val_accuracy: 0.2633\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.33333\n",
            "Epoch 135/4000\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.8094 - accuracy: 0.6930 - val_loss: 2.6582 - val_accuracy: 0.2600\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.33333\n",
            "Epoch 136/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.7111 - accuracy: 0.7613 - val_loss: 2.6624 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.33333\n",
            "Epoch 137/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.7553 - accuracy: 0.7312 - val_loss: 2.5427 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.33333\n",
            "Epoch 138/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.7596 - accuracy: 0.7215 - val_loss: 2.5903 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.33333\n",
            "Epoch 139/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6859 - accuracy: 0.7665 - val_loss: 2.7046 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.33333\n",
            "Epoch 140/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.6842 - accuracy: 0.7701 - val_loss: 2.6288 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.33333\n",
            "Epoch 141/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6265 - accuracy: 0.7787 - val_loss: 2.7670 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.33333\n",
            "Epoch 142/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.7682 - accuracy: 0.7323 - val_loss: 2.6674 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.33333\n",
            "Epoch 143/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.7368 - accuracy: 0.7313 - val_loss: 2.5116 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.33333\n",
            "Epoch 144/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.7516 - accuracy: 0.7351 - val_loss: 2.7224 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.33333\n",
            "Epoch 145/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.7091 - accuracy: 0.7569 - val_loss: 2.6024 - val_accuracy: 0.2900\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.33333\n",
            "Epoch 146/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.7592 - accuracy: 0.7353 - val_loss: 2.6846 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.33333\n",
            "Epoch 147/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.6865 - accuracy: 0.7680 - val_loss: 2.4281 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.33333\n",
            "Epoch 148/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.7106 - accuracy: 0.7446 - val_loss: 2.7274 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.33333\n",
            "Epoch 149/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.6484 - accuracy: 0.7514 - val_loss: 2.6883 - val_accuracy: 0.2900\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.33333\n",
            "Epoch 150/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6891 - accuracy: 0.7619 - val_loss: 2.7265 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.33333\n",
            "Epoch 151/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.6470 - accuracy: 0.7872 - val_loss: 2.5624 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.33333\n",
            "Epoch 152/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6754 - accuracy: 0.7632 - val_loss: 2.7061 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.33333\n",
            "Epoch 153/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.7222 - accuracy: 0.7299 - val_loss: 2.7141 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.33333\n",
            "Epoch 154/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7295 - accuracy: 0.7401 - val_loss: 2.8662 - val_accuracy: 0.2967\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.33333\n",
            "Epoch 155/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6746 - accuracy: 0.7903 - val_loss: 2.7601 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.33333\n",
            "Epoch 156/4000\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.6536 - accuracy: 0.7775 - val_loss: 2.8327 - val_accuracy: 0.3467\n",
            "\n",
            "Epoch 00156: val_accuracy improved from 0.33333 to 0.34667, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 157/4000\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.7364 - accuracy: 0.7381 - val_loss: 2.8807 - val_accuracy: 0.2900\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.34667\n",
            "Epoch 158/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.7137 - accuracy: 0.7505 - val_loss: 2.7471 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.34667\n",
            "Epoch 159/4000\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.6545 - accuracy: 0.7786 - val_loss: 2.8118 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.34667\n",
            "Epoch 160/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7214 - accuracy: 0.7421 - val_loss: 2.6815 - val_accuracy: 0.3433\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.34667\n",
            "Epoch 161/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.6133 - accuracy: 0.7732 - val_loss: 2.6323 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.34667\n",
            "Epoch 162/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6695 - accuracy: 0.7501 - val_loss: 2.6975 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.34667\n",
            "Epoch 163/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5679 - accuracy: 0.8016 - val_loss: 2.7235 - val_accuracy: 0.3567\n",
            "\n",
            "Epoch 00163: val_accuracy improved from 0.34667 to 0.35667, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 164/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5941 - accuracy: 0.7832 - val_loss: 2.6290 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.35667\n",
            "Epoch 165/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5194 - accuracy: 0.8283 - val_loss: 2.7610 - val_accuracy: 0.3433\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.35667\n",
            "Epoch 166/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6481 - accuracy: 0.7707 - val_loss: 2.6609 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.35667\n",
            "Epoch 167/4000\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.5845 - accuracy: 0.7886 - val_loss: 2.7001 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.35667\n",
            "Epoch 168/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5798 - accuracy: 0.7942 - val_loss: 2.7776 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.35667\n",
            "Epoch 169/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6325 - accuracy: 0.7986 - val_loss: 2.7528 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.35667\n",
            "Epoch 170/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5839 - accuracy: 0.8071 - val_loss: 2.9012 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.35667\n",
            "Epoch 171/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6640 - accuracy: 0.7632 - val_loss: 2.7112 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.35667\n",
            "Epoch 172/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6102 - accuracy: 0.7727 - val_loss: 2.8526 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.35667\n",
            "Epoch 173/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5619 - accuracy: 0.8138 - val_loss: 2.7715 - val_accuracy: 0.2967\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.35667\n",
            "Epoch 174/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6079 - accuracy: 0.7830 - val_loss: 2.7403 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.35667\n",
            "Epoch 175/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6374 - accuracy: 0.7628 - val_loss: 2.8253 - val_accuracy: 0.2900\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.35667\n",
            "Epoch 176/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5467 - accuracy: 0.8076 - val_loss: 2.7900 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.35667\n",
            "Epoch 177/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5602 - accuracy: 0.8072 - val_loss: 2.7672 - val_accuracy: 0.3700\n",
            "\n",
            "Epoch 00177: val_accuracy improved from 0.35667 to 0.37000, saving model to /content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5\n",
            "Epoch 178/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6171 - accuracy: 0.7978 - val_loss: 2.6414 - val_accuracy: 0.3233\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.37000\n",
            "Epoch 179/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6625 - accuracy: 0.7635 - val_loss: 2.7368 - val_accuracy: 0.3567\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.37000\n",
            "Epoch 180/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6144 - accuracy: 0.7817 - val_loss: 2.7433 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.37000\n",
            "Epoch 181/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6687 - accuracy: 0.7644 - val_loss: 2.9681 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.37000\n",
            "Epoch 182/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6174 - accuracy: 0.7846 - val_loss: 2.6728 - val_accuracy: 0.3433\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.37000\n",
            "Epoch 183/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5031 - accuracy: 0.8319 - val_loss: 2.9977 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.37000\n",
            "Epoch 184/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5970 - accuracy: 0.7844 - val_loss: 2.7827 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.37000\n",
            "Epoch 185/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4966 - accuracy: 0.8275 - val_loss: 2.8813 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.37000\n",
            "Epoch 186/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4725 - accuracy: 0.8317 - val_loss: 3.0125 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.37000\n",
            "Epoch 187/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5752 - accuracy: 0.8106 - val_loss: 2.7965 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.37000\n",
            "Epoch 188/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5131 - accuracy: 0.8269 - val_loss: 3.0247 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.37000\n",
            "Epoch 189/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4844 - accuracy: 0.8406 - val_loss: 2.7959 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.37000\n",
            "Epoch 190/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4901 - accuracy: 0.8346 - val_loss: 2.9507 - val_accuracy: 0.3433\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.37000\n",
            "Epoch 191/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5679 - accuracy: 0.8128 - val_loss: 2.9227 - val_accuracy: 0.3567\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.37000\n",
            "Epoch 192/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4847 - accuracy: 0.8291 - val_loss: 2.9108 - val_accuracy: 0.3467\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.37000\n",
            "Epoch 193/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5839 - accuracy: 0.8031 - val_loss: 2.8814 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.37000\n",
            "Epoch 194/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5106 - accuracy: 0.8519 - val_loss: 3.2133 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.37000\n",
            "Epoch 195/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4790 - accuracy: 0.8292 - val_loss: 3.0289 - val_accuracy: 0.2967\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.37000\n",
            "Epoch 196/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.6225 - accuracy: 0.7765 - val_loss: 3.0170 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.37000\n",
            "Epoch 197/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.5359 - accuracy: 0.7924 - val_loss: 2.8483 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.37000\n",
            "Epoch 198/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4291 - accuracy: 0.8537 - val_loss: 2.8302 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.37000\n",
            "Epoch 199/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5280 - accuracy: 0.8091 - val_loss: 2.7617 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.37000\n",
            "Epoch 200/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5631 - accuracy: 0.8074 - val_loss: 3.0272 - val_accuracy: 0.3467\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.37000\n",
            "Epoch 201/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5083 - accuracy: 0.8277 - val_loss: 2.9680 - val_accuracy: 0.3567\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.37000\n",
            "Epoch 202/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4388 - accuracy: 0.8534 - val_loss: 3.1016 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.37000\n",
            "Epoch 203/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4733 - accuracy: 0.8352 - val_loss: 2.9915 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.37000\n",
            "Epoch 204/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4299 - accuracy: 0.8520 - val_loss: 3.0437 - val_accuracy: 0.3467\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.37000\n",
            "Epoch 205/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5034 - accuracy: 0.8300 - val_loss: 3.0315 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.37000\n",
            "Epoch 206/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4244 - accuracy: 0.8547 - val_loss: 3.1905 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.37000\n",
            "Epoch 207/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5191 - accuracy: 0.8294 - val_loss: 3.0345 - val_accuracy: 0.3633\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.37000\n",
            "Epoch 208/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4866 - accuracy: 0.8356 - val_loss: 3.1697 - val_accuracy: 0.3633\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.37000\n",
            "Epoch 209/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5177 - accuracy: 0.8220 - val_loss: 3.0838 - val_accuracy: 0.3367\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.37000\n",
            "Epoch 210/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4466 - accuracy: 0.8415 - val_loss: 3.2024 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.37000\n",
            "Epoch 211/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5577 - accuracy: 0.8106 - val_loss: 3.1083 - val_accuracy: 0.3433\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.37000\n",
            "Epoch 212/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4601 - accuracy: 0.8341 - val_loss: 3.1553 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.37000\n",
            "Epoch 213/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5176 - accuracy: 0.8282 - val_loss: 3.1480 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.37000\n",
            "Epoch 214/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4727 - accuracy: 0.8262 - val_loss: 3.0456 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.37000\n",
            "Epoch 215/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4801 - accuracy: 0.8431 - val_loss: 3.0226 - val_accuracy: 0.3367\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.37000\n",
            "Epoch 216/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5326 - accuracy: 0.8082 - val_loss: 3.0449 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.37000\n",
            "Epoch 217/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4246 - accuracy: 0.8584 - val_loss: 3.0055 - val_accuracy: 0.3700\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.37000\n",
            "Epoch 218/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4354 - accuracy: 0.8563 - val_loss: 3.1203 - val_accuracy: 0.3233\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.37000\n",
            "Epoch 219/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4229 - accuracy: 0.8527 - val_loss: 3.1276 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.37000\n",
            "Epoch 220/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4430 - accuracy: 0.8597 - val_loss: 3.0244 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.37000\n",
            "Epoch 221/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4251 - accuracy: 0.8611 - val_loss: 2.9733 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.37000\n",
            "Epoch 222/4000\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4924 - accuracy: 0.8336 - val_loss: 3.3140 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.37000\n",
            "Epoch 223/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4664 - accuracy: 0.8431 - val_loss: 3.1203 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.37000\n",
            "Epoch 224/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3428 - accuracy: 0.8907 - val_loss: 3.0327 - val_accuracy: 0.3467\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.37000\n",
            "Epoch 225/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3685 - accuracy: 0.8739 - val_loss: 3.0870 - val_accuracy: 0.3233\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.37000\n",
            "Epoch 226/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4974 - accuracy: 0.8296 - val_loss: 3.2831 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.37000\n",
            "Epoch 227/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4551 - accuracy: 0.8446 - val_loss: 3.0727 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.37000\n",
            "Epoch 228/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4547 - accuracy: 0.8539 - val_loss: 3.2846 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.37000\n",
            "Epoch 229/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4959 - accuracy: 0.8502 - val_loss: 2.9377 - val_accuracy: 0.3233\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.37000\n",
            "Epoch 230/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5070 - accuracy: 0.8460 - val_loss: 3.0119 - val_accuracy: 0.3200\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.37000\n",
            "Epoch 231/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4769 - accuracy: 0.8423 - val_loss: 3.2755 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.37000\n",
            "Epoch 232/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4213 - accuracy: 0.8696 - val_loss: 3.1631 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.37000\n",
            "Epoch 233/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3292 - accuracy: 0.9174 - val_loss: 3.0659 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.37000\n",
            "Epoch 234/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4077 - accuracy: 0.8760 - val_loss: 3.1704 - val_accuracy: 0.3367\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.37000\n",
            "Epoch 235/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4275 - accuracy: 0.8538 - val_loss: 3.2070 - val_accuracy: 0.3067\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.37000\n",
            "Epoch 236/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4061 - accuracy: 0.8619 - val_loss: 3.1393 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.37000\n",
            "Epoch 237/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5455 - accuracy: 0.8333 - val_loss: 3.1825 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.37000\n",
            "Epoch 238/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.3755 - accuracy: 0.8832 - val_loss: 3.1122 - val_accuracy: 0.3433\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.37000\n",
            "Epoch 239/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.3707 - accuracy: 0.8865 - val_loss: 3.3437 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.37000\n",
            "Epoch 240/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4110 - accuracy: 0.8830 - val_loss: 3.1211 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.37000\n",
            "Epoch 241/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4406 - accuracy: 0.8540 - val_loss: 2.9752 - val_accuracy: 0.3600\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.37000\n",
            "Epoch 242/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.3308 - accuracy: 0.8872 - val_loss: 3.2413 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.37000\n",
            "Epoch 243/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4173 - accuracy: 0.8574 - val_loss: 3.1037 - val_accuracy: 0.3567\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.37000\n",
            "Epoch 244/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3644 - accuracy: 0.8756 - val_loss: 3.1406 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.37000\n",
            "Epoch 245/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3560 - accuracy: 0.8867 - val_loss: 3.3002 - val_accuracy: 0.3233\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.37000\n",
            "Epoch 246/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.3768 - accuracy: 0.8810 - val_loss: 3.2032 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.37000\n",
            "Epoch 247/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4175 - accuracy: 0.8613 - val_loss: 3.2106 - val_accuracy: 0.3367\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.37000\n",
            "Epoch 248/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.4186 - accuracy: 0.8678 - val_loss: 3.2230 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.37000\n",
            "Epoch 249/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.3928 - accuracy: 0.8605 - val_loss: 3.1903 - val_accuracy: 0.3033\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.37000\n",
            "Epoch 250/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4024 - accuracy: 0.8587 - val_loss: 3.2284 - val_accuracy: 0.3367\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.37000\n",
            "Epoch 251/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.3671 - accuracy: 0.8865 - val_loss: 3.2919 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.37000\n",
            "Epoch 252/4000\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4607 - accuracy: 0.8512 - val_loss: 3.2705 - val_accuracy: 0.3267\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.37000\n",
            "Epoch 253/4000\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.3414 - accuracy: 0.8706 - val_loss: 3.3140 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.37000\n",
            "Epoch 254/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.3045 - accuracy: 0.9137 - val_loss: 3.2664 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.37000\n",
            "Epoch 255/4000\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.2880 - accuracy: 0.9213 - val_loss: 3.3879 - val_accuracy: 0.3633\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.37000\n",
            "Epoch 256/4000\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.3462 - accuracy: 0.8947 - val_loss: 3.2560 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.37000\n",
            "Epoch 257/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.3594 - accuracy: 0.8829 - val_loss: 3.3814 - val_accuracy: 0.3600\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.37000\n",
            "Epoch 258/4000\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.3729 - accuracy: 0.8702 - val_loss: 3.1610 - val_accuracy: 0.3667\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.37000\n",
            "Epoch 259/4000\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3951 - accuracy: 0.8675 - val_loss: 3.4692 - val_accuracy: 0.3167\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.37000\n",
            "Epoch 260/4000\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4111 - accuracy: 0.8613 - val_loss: 3.3818 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.37000\n",
            "Epoch 261/4000\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.3041 - accuracy: 0.9041 - val_loss: 3.3418 - val_accuracy: 0.3533\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.37000\n",
            "Epoch 00261: early stopping\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_11 (LSTM)               (None, 25, 128)           86528     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 25, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 136,586\n",
            "Trainable params: 136,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8Xre_2FC3FgP",
        "outputId": "916050bb-3757-47e4-f18c-2cc965dcb3aa"
      },
      "source": [
        "saved_model = load_model('/content/drive/MyDrive/Project/miracl-vc1-copy/new_split/best_model.h5')\n",
        "_, train_acc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = saved_model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, val_acc))\n",
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.881, Test: 0.370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xUVfr/32cmk957hQQIvROaFBUsqIgFe1l1dVnbqru6u+p3V9dddf256tp77wUbKqyIgIg0Qw29hEASCOm9J+f3x5nJpJJAGgnP+/Wa151777l3zuQFn/vMc56itNYIgiAIPR9Ld09AEARB6BhE0AVBEHoJIuiCIAi9BBF0QRCEXoIIuiAIQi/Bpbs+ODg4WMfGxnbXxwuCIPRI1q9fn621DmnuXLcJemxsLImJid318YIgCD0SpdSBls6Jy0UQBKGXIIIuCILQSxBBFwRB6CW06kNXSrkDKwA3+/j5WusHG425HvgPkG4/9LzW+vVjnUxVVRVpaWmUl5cf66U9Dnd3d6Kjo7HZbN09FUEQegltWRStAGZorYuVUjZgpVJqkdZ6TaNxn2itb2/PZNLS0vDx8SE2NhalVHtudUKjtSYnJ4e0tDTi4uK6ezqCIPQSWnW5aEOxfddmf3VKRa/y8nKCgoJ6tZgDKKUICgo6KX6JCILQdbTJh66UsiqlNgGZwA9a67XNDJurlNqilJqvlIpp4T7zlFKJSqnErKyslj6rrXPv0Zws31MQhK6jTYKuta7RWo8GooEJSqnhjYZ8A8RqrUcCPwDvtHCfV7XWCVrrhJCQZuPiBUEQeh9V5bDhPait7dSPOaYoF611PrAMmNXoeI7WusK++zowrmOm17Xk5+fz4osvHvN15557Lvn5+Z0wI0EQegV7FsOC2yFlRad+TKuCrpQKUUr52997AGcCOxuNiai3OwfY0ZGT7CpaEvTq6uqjXrdw4UL8/f07a1qCIPR0yvLMNq1zs+PbEuUSAbyjlLJiHgCfaq2/VUr9E0jUWi8A7lBKzQGqgVzg+s6acGdy7733sm/fPkaPHo3NZsPd3Z2AgAB27tzJ7t27ufDCC0lNTaW8vJw777yTefPmAc4yBsXFxZxzzjlMnTqVVatWERUVxddff42Hh0c3fzNBELqVikKzTd/QqR/TqqBrrbcAY5o5/kC99/cB93XkxB76ZhvbDxV25C0ZGunLg+cPa/H8Y489xtatW9m0aRPLly/nvPPOY+vWrXWhhW+++SaBgYGUlZUxfvx45s6dS1BQUIN77Nmzh48++ojXXnuNyy67jM8//5xrrrmmQ7+HIAg9jPICs01PBK2hk4IiJFP0KEyYMKFBnPizzz7LqFGjmDRpEqmpqezZs6fJNXFxcYwePRqAcePGkZKS0lXTFQThRCH1V6ebBaDcbpwWH4HC9Oav6QC6rdpiaxzNku4qvLy86t4vX76cJUuWsHr1ajw9PTnttNOajSN3c3Ore2+1WikrK+uSuQqCcIJQVQZvnQNT7gCbB2TuAEu9jPCUX2DU5Z3y0WKh18PHx4eioqJmzxUUFBAQEICnpyc7d+5kzZrGibKCIAhAzj6orYLs3bB7MST/ZHzoocMgsD+sfcm4XTqBE9ZC7w6CgoKYMmUKw4cPx8PDg7CwsLpzs2bN4uWXX2bIkCEMGjSISZMmdeNMBUHocJKXQ3UFDDy7fffJsbtic/dD0WHjeinLA48AGHEJfHsX7F8B/U5t95QbI4LeiA8//LDZ425ubixatKjZcw4/eXBwMFu3bq07fs8993T4/ARB6CR+etxY0u0V9Oy9Zpu1y1jqAHkpEDkGRl0Jy/8N+5aKoAuCINSxezFkboepd3XM/UqyoaJ5l2ubyE2G5Y857+EQczCWutupYHOHW1aBV3D75toCIuiCIPRMtnwMe3/sOEEvzTbRKM2FFa5+AYoz4cyHml5XnAmVxfDzk7DlE3PMxR2qGwVNuPuZbSeJOciiqCAIPZWKIijPN35vB/+7D/b8AJs+hK/rVfM+vAWqK1u+V22N8XPXVjmTgOqz7UtY/1bzi5lfzIOXpsCWz5zH4qY3Hefu2/p3aici6IIg9Ewcro3iI2ZbWwNrX4btX8Hu72HHAnO8JAdePQ02vtvyvcryQdsLZ5VkNz1fkGaSg/Ib9WcuL4CUn6GqFGoqYPxN5ni/08HiAm5+zrHufnQ24nIRBKFnUifomeDfxwixrrX7wovNea2hJBN0DWQktXyv0noiXpINQf2hNBc8A41lX5Rhzh3eAgGxzrH7lkFtNVz0qrHAY6dCZQkMmQ3r34aAvuYXAxrcxEIXBEFoHodrxCG2Dku9ONMu4rXGcnZkbGbubHoPB6U5zvclWSaW/D/9IXUdFB2irqdPxpaG1+1ZbCzv4XNh0Dng5gMXvWweMJe+Dec+YR4KIC6XEx1vb+/unoIgdA+VpcY67U4au1wc25JsI8pgLHWHoGftbDmhp76bpTQb8vabB8LhzVBQL1U/LRF+fgr+Xxxs+wp2fgvxZ4O1GWdH2FBjoXvZez90gctFBF0QhGMn6TN478KGYne8bF8Aa185tmu0blnQizOcIl5R5Hxfnu8cs/ULeHKI81xjC73M3t8gd7/xnwNEJUDyMvjxIZPeP/+3xoc++dajz9XTHtXiJj70LuXee+8lJiaG2267DYB//OMfuLi4sGzZMvLy8qiqquLhhx/mggsu6OaZCkI34xDAwnTwi2r7denrTVTITUtM5iSYhcyMrTBhXturEFaXG981NHW51NSLZqkobFgkK2sneAbBkgeNK8XxKyPbnt3p4m4WUd3t/Q3y9jtdJjP/DknzTbZndQV8eBnEn2USho6GI0zxpF4UXXTv0RcxjofwEXDOYy2evvzyy7nrrrvqBP3TTz/l+++/54477sDX15fs7GwmTZrEnDlzpCeocHLjsI4dYtpWDqyGnL2mYFXKShh0rsmorCgw4hnY79g+H4zPvP628bgGgr4L8g+al7Ia98mRJFAWcPUx4lua7RTxvBTwDjNWdr/TzAvML4Q5zzUfntiYOpdL5/vQT1xB7wbGjBlDZmYmhw4dIisri4CAAMLDw/njH//IihUrsFgspKenc+TIEcLDw7t7uoLQfTRekGwrDvfFoU2w7BFjtDkiTLZ9aRpAxJ8FY39zdGu9gaBntDyXSrsP3TPI+MSPbDP7/n0hYiTs+MaM07VGxL2CjcvFIcJ5KeAbCX7RDe+rlJljW/CNBKvrSW6hH8WS7kwuvfRS5s+fT0ZGBpdffjkffPABWVlZrF+/HpvNRmxsbLNlcwXhpKLOQj98bNcVpJrtfntvzd3/c55b9m+T2LPzW2PNDrvoKJ9vf6B4BDa00N38jLVff55leWacT7h5gJQXGDHvP9MIurufOeYVbCzxgjSnVV9Vah4yfU85tu9Zn/E3mbotLm6tj20nsijaiMsvv5yPP/6Y+fPnc+mll1JQUEBoaCg2m41ly5Zx4MCB1m8iCL2d8nZa6Ad+MVuHv9szyIj5iEvB6mZ87fWpLIUvb4bH+hhXjeOBEhxvfOe1tWYb1qiPQp2gB0DEKGOh5yZD2HAYegGMvAJmP+2cg8NCr++mKct1ulqOB3dfiBp3/NcfAyLojRg2bBhFRUVERUURERHB1VdfTWJiIiNGjODdd99l8ODB3T1FQeh+2mqhH1zb0D3iEPT66fVWNxPDDZBwI4QONouk9dn+NWz+yFjSycud9wwdahZH8w8YC90h6Mrq/ByHoIePNNmcaHOdZyBc/AoMng2u3uAdaqz4kkwj6r52N4tPJIy59lj+Ot3Giety6UaSkpyLscHBwaxevbrZccXFxV01JUE4saio11KtJcryTeee0++D6X82oX71MzId7pGgAcYt4R0GfSZB2AiTsFOfrJ2m609ArBH7oAHmeNx0U2MlZSVUFpmIG49AcPUyDxtHHHrIEONmcVDfkndxhWs+B58I2P+T8adn7oD+M4x1PfWPpkpiD0AEXRCEY6duUfQoFnpusj3l3m5tO2LWPYNM2GP4CCO2kaNN6J8j/C9sGGx631jc3qHmWPZuI+Jhw0z25oCZ5nifSSbUcP3bZj8g1ixounqZBdGKIvNg8QiAoHgzVlkgwNkruO4+AHl9zbaq1Nznig+O9y/ULYjLRRCEY8fh8ijLg6oWggRyk802c4fZOhZE+0w228BYuO4bOOfxhteFDzfbI/XcLlk7IWSgEfSCg07XjUeg8Y2nJxqxHnCGcd/En2XS8MtyzcPHI8Bkc0aMNq4XSwvS59/H+d7Dv9U/w4nGCWeha61Pihhv3Uk9BQWhS6goMhZsSZYJG6xfsMpB3n6zzd0HG96FxX83+30mm0iWgDjwCmp6XZhd0FN+MfVX8lLMa8SlznOpa40LxsXNZHCmrnWKuKNm+c5v6wm/PYnp4leP/r38oo0Fr2ud1/QgWrXQlVLuSql1SqnNSqltSqkmFd6VUm5KqU+UUnuVUmuVUrHHMxl3d3dycnJ6vdhprcnJycHdvWf45YSTlOIs2PBe0+NV5SY6JXig2d/zQ8MaKfkHYeFfnMWwaqvhu7tN6j1A3DSzDWkhwMAz0CxUrnwKvr8P1r1iBDZ4oNP3fXC1EW+lINoeQTL84ob3cfOBfPuvAoc4B/Q1r5aw2pyLoT1Q0NtioVcAM7TWxUopG7BSKbVIa12/7f2NQJ7WeoBS6grg/wGXH+tkoqOjSUtLIysr61gv7XG4u7sTHR3d+kBB6GrWvWYSYSoKYfHfIP5ME/3hwOFuiT/L+JoX3mP84g5BXflfSHzTvPcING6Pmko47X7jTokYBTctPXrK/IUvwpvnmDDCw5tMdEvIYJOk4xNhb+nmY8YOmQOXvAlDGpXkcPW2V0rk2MTZv49x6/RGQdfGXHaEc9jsr8Ym9AXAP+zv5wPPK6WUPkZT22azERcX1/pAQRA6jsJD8NWtRhQ9A2HNS0bMYqeY8yVZjQTdviDqEwE3LoFHI4zoOgTds16LtQEzTSEsN2/TKs6RXBPdSly2ux/8fgVYrLDiP7D6ebMoqpQpVbv6eWctF6vNHGuMQ/ABAo9BVwL6woGVPVLQ27QoqpSyKqU2AZnAD1rrtY2GRAGpAFrraqAAaOIcU0rNU0olKqUSTwYrXBB6BOnrTRXBQxuhxh7TXZJlilRB0w4+DkF38zELjT4R5qHgoLLE+T50iGn6MO76Y8+UtLoYAZ/+Z7gryRk6OOoKsy1spdKjQ9B9o9peIwZMWQDokYLepkVRrXUNMFop5Q98qZQarrXe2tp1zdznVeBVgISEhN7tKBeEE53VLxhf9EB7Uk9JtolEqa027x0x4/VLy4LT5eIQTL/ohoJeP8sysB9Mu7t981SqYR2U8BFmGz3+6Nc55hc7te1VHAFiJhgXUuP6LT2AYwpb1FrnA8uAWY1OpQMxAEopF8APaPSvQBCEE4qUX+xp9HaLuyTTRKQAVJU4FxQL0+HNWbBzodkvr2ehg/FrO6JJwAh66FCY/V/nw6KjuS8drvv26GMcMfKOMMm20v90+EtylxTT6mjaEuUSYrfMUUp5AGcCjXs5LQCus7+/BFh6rP5zQRC6mNJss9joEOiSLNPQwUGOvUZ42q/Gkv/4Snu/TruF7igH6xtpxLPW3mS5PN8sZib8tvMyLN28W7+3o4enI2noJKAtLpcI4B2llBXzAPhUa/2tUuqfQKLWegHwBvCeUmovkAtc0WkzFgShY3A0VXZEgpRkQ02V87yjcNahzc5jb53rLDTlEEzfKDO2NAe8Q+yp9oM6f/6tceY/YdiFxo9/ktCWKJctQJP4Iq31A/XelwOXduzUBEFoMwfXwJZP4bwn2+4vdvjIHa6Vkiwj6spqUvYdFBw02wtehGWPwuYPzX79RUcwrhmHoLufAFmW7r7tq5LYA5HUf0E4UUjfYOqUHA9bv4DENxpWMTwa1ZXG3QLOlPySLJOuX7+IlQOLDUZdCVd94jzmiFrxjTTbwnSTYOSobih0OSLogtBdVFeaFmiVpcb/PP8G+Oau47tXvt2KLjpK9cP61I9ccVjoBekmXb/+IqLFZrZ+Uab+SfhwmPonU4nQQZ2FfsgkGtVUiqB3EydcLRdBOGlI+dl0kPfvY6oK5qWAi4exco+1npFD0PMPwJoXYNo94B/T8vj6ZWyry8y2xN75J3q8ybKsLDbJPFk7wK/evc54sOG9vEKM8Nfv9COC3i2IhS4I3YVDhDO3O2umVJcdexcgrZ332v29KSW75ZOjXtIkWag+EaOcneodi5t+R3k4WCwmNjzxLVPXBUTQuwkRdEHoLhy+68ObYddCZ43u3H0Nk3NaoyzPNHcASLWXWHL44pc+YmqiOEIKHTROFrK6mq2rt70Kor1JsqOA1tGsfYDL3gUPP/jW7jISQe8WRNAFobtw+K73LTPujYQbzP7PT8ETg9ruD3dY52B6ZoIpJ1tba5ogH1wFW+c3vKaxhe54mIQNNxa3V4iJdgnqb44fzUIHI/jjb3Lui6B3CyLogtBdOITYESI46kqwuMC+H03vy8ztbbyPo3G5MnHlYJJ70tebxhAASx9u2NuzJMvU/bZ5mX2HcDvS6v37mtR3R8MHR8u3o1F/oVQEvVsQQReE9lBZaopaHQ8FqaZmCJg+mt6hDTvmODr+HI0PLoNPf2PeO9wj3mFmu/p5QJsF0oJU+PJmp+ulNNt8tkN4Q4eaBVlHhcXT74Prv4WYifDbxW3Ltgyt16dTBL1bEEEXhPaw/i14bebRFxmbo7rShPnFn2X246abbf2qgM0J+qGN8PwEKM01ceR7f3Cecyxg9jsdAvvD9q8ABVPugJkPmA4+hzaYMSXZpsyto81aQF+4eycMvdDsu/uZh4tS0Gdi26JuLBbjpgGwebTpzyB0LCLogtAesnbZGyFvObbrCtMBDX2nwKzHYNIt5nhQvAkB9OvTvKDvXwHZu8yiZ+o642LxCjW9NB01ywNiYda/zfuQQUacB59v9rN3w+7FkJZoIlkcBajcfI24t7f9452b4er57b+PcFyIoAtCe8hLMduMJLPd8S1k73WeLzoC75wPOftMW7Yd9gqBjggX/z5GzB1RJNPuhhsWmmzNnH3O++xeDNu+dIp8RhIcWGV87nduMiLqcLUExMLAs2HiLZBwo/1YX2M9H9kGn1xtolrG31RP0Os1g2gP/jGmw5HQLUhikSAcD0e2G1GsL+hawxe/g2EXw4UvmOMHVxur+rmxZj/pM9MXc+kjZr9xf0vvEPMK7Ad7FkNtDeTsNX5yD38Ijrd/fhIUZ5ou9q72hc36FjrAOY8572u1meM7FphMzrMfgaFzYPf/zPkeWCpWaIoIuiAcD1/MMx11HHXAM5JM6GFVqXFr1FQZ4axfvRCMBbvyKRN7Pusxp/g2JrCfub4wHRb8wZ5wVAYV9m6QB9eaXp0Tf++8Jv5sOOUPzmqIjQkaAHu+N+8jRpltfZeL0OMRl4sgHCs11caPfWij8Z/7RhsRd4QhZu+Gpf8yi6WOTvcOSrJNzfHwEU6/eXM4wgiTl5uY8gF2N0ZlkUn+Kc4wgj/6Guc1XkFw1sPg4trCPe2hh+7+zmiajna5CN2KCLogtEZBuvF/f3y1iSzJS3HWCgcYcr5ZnNz/s9kvzzelbHP2OgX9rwdM+GDRYSPojV0tjYkaB64+sOQfZn/6Pc5zA88228GzIXRw27+H4yERMcq5aBk6BLzDTXNooccjgi4IrbH6eVj3ign7O7jGmazjwJFQk/ar81jRYaitMqGJLu7G/+0XZYS/MM3ZiLglXL1Mc4bSHPCJNPHgDgt79NXmM2f87di+h+N6h7sFYNhFcM+uY2/gLJyQiKALQmO0hrdnw9bPzX7yT04RzN7jFPTgQWB1g+gEs++I8a5PXorTreFbr+lwaxY6wBi7O2XATGNRO+YQOQau/fLYO/GEjzAJPwNmHtt1Qo9BFkUFoTGVxaa0bdAAiJ0Omdtg5oNmATR7N1SXG3Geehcc2mRE0tXHGVJodTOp+9BQ0P2inJ/RmoUOxiqf+YAzhnzUlSZG/XjdI56B8NeU47tW6BGIoAtCY4rtdcGLMmD/T+Z9v1NNGGH2HqgqMQk7o68yLzDRK5nb7QuOMSasUdeYhdJIewdH33qC3hYLXSkTl+4g/kyJ8RaOirhcBKExdYJ+GFJWgpufifcOjjeinbWrqbvDz+5O8Q6F856COc+a/dpqp4Xu7mciVJS1oftFEDoIsdAFoTEl9Sz07D0QNhQsVgge6IxaGXZRw2sc5WW9QiFmQkOXikPQlTJWenWZiWEXhA5G/lUJQmMcFrpD2PufbrZB9izNkCFNk3ccqfuOTj/1qw3Wz8KMner0rwtCB9OqoCulYoB3gTBAA69qrZ9pNOY04Gtgv/3QF1rrf3bsVAWhAyhIM7HdA84wAh0x0qTF16cky2x1rUngqWv+MMzUEE+4oWnxKYeF7h1qti6uzr6c9QV99lMd/pUEwUFbLPRq4G6t9QallA+wXin1g9a6cfX9n7XWszt+ioLQgexdYuqpJH1m9mc+0HDhEaC4UacgR3q+fwzcurb5Zg/1XS4OPAKbCrogdCKtLopqrQ9rrTfY3xcBO4Coo18lCCcoxXbr+7ffm3opqetMk4rygoZjVL3/GoFxzvchA03d78YE9TfFuoLq1TN31BqXOilCF3FMUS5KqVhgDLC2mdOTlVKblVKLlFLDmjmPUmqeUipRKZWYlZV1zJMVhGbZ/jWU5LQ+Doxf3M3PdOCJnmDqsSy4HZ4eYWqEO8Y4/OXgdLkcDa9guHMLDK23WOqIFxcLXegi2izoSilv4HPgLq11YaPTG4C+WutRwHPAV83dQ2v9qtY6QWudEBIScrxzFgQnJTmmtOyGd5o/n7wcyvLMdttXZsHT2/5vL3KMca9sX2As9HcvMGGKxUeMvxxlem46FjpbwzeiofXuWBh19z/OLycIx0abBF0pZcOI+Qda6y8an9daF2qti+3vFwI2pVQb/xcIQjsoOmS2helNz2UkGZH++SlY/Df44e9mwdPh544cbba1VXDBCyak8P25JhnINxK8Qoy75Xi773iIhS50LW2JclHAG8AOrXWzS/RKqXDgiNZaK6UmYB4UbfwNLAjtoPBwwy2YbveL/+70g2/7CgoOmoQeZTWRLWBqmygL2DxhxKWmRO3Tw805r2Bjpfu1Y7lIXC5CF9OWKJcpwLVAklJqk/3Y/UAfAK31y8AlwC1KqWqgDLhCa607Yb6C0JAiu5A7LHWAFU/CgV/Me88gI+ZgUvHz9puQRTAVDaMSzIKmixv4hMHp/wdLHjQLmVd90nBx9Fjxsrt26sekC0In0qqga61XAkf9zam1fh54vqMmJQhtpk7QM8y2IA12L4Ix1xpBjZsO713Y8BrveqGF1y1wdqoHOOUOkxHa//T2l5QddYUpCeAt60VC19AjM0XT8kqJDvDs7mkIJwIOQS8+YjoJbfrIlL+dfo+JH9fa1BP3DjFt38BpOQPYPBrez2KBwed2zNzc/WDweR1zL0FoAz2uONcXG9KY9vgy9mYWdfdUhO6iOBNS7c0kHJa5rjXhhsnLzGKnIxlIKbj+W7jqU7DY7Zf6Frog9CJ6nKCfOjAEV6uFN1bub32w0LMpyYak+U2Pf3c3vDvHNGAuPOQU6rwUE0ved0rD8UH9wSfcWRHRSwRd6J30OEEP8nZj7rhoPt+QTmZheXdPR+gsaqpMD8/PbzS1xR2U5MCuRVBVCke2GQs9zJ7HtuMbU/gqdmrz93RY7eLTFnopPU7QAW6aGgcarn1jHec9+zM3v7ee4orq7p6W0JGsfh5S15j3+5Y6jyd9auLGwaTtl2Q5Kx8mfQYo6DO5+Xs6BF0sdKGX0vMWRY9so9/6t1k4OZyX1+Vj9fAh+0gl9/17Mb6+vlQqNwZG+FFWpVHKgq+nK+F+ngyM8KOiWhPs68GmtEJAYbG6UFWr8fd0x93Vyt6sUrw9XBka4Ud0oBdV2kqFcqUKV9xtFiqKcrC42PD1DUAlvgHLHqFq9G+wzbgfbO7d/ZfpXexbBuEjobrCCPopt5v3a182zSbyD8KuhYA28eTgFHePFjIzh15gGk64yoK60DvpeYKesw82fcSAyiKesAAVgKP6qaMgQUHzlzo4o4Xjoxrtu9pftVpRhQsByliGWSqQYJ1HiVcM3qufYeeBg1SGjsK/31gih02joKyKIG/pon7caA0ZW2DI+SbpZ/3bUFUOa140fvJrv4TVL5oFUAD/PqbaYUEqXPxay/ftP8O8BKGX0vMEfegc8x+9ONPU36iwR7sooKoMqsqoqanBqgBdi9Y1pOeWciivGFcXRU5ROXFBHnjaFLW1tbgoTXF5FRVVVYT5uFFRVc2B7GJKyitxtdTiRiWutRVQXU6lezC6tpaK1PUUlVVwd84t3O36Bb879CUc+pLcLYGs/uU8PDPWsfnSz5kxPKY7/1I9l4JUU38lfKTp/LP2ZfNa8QQMOs+I8sG1sPcH6Hc6xJ0KNy0BNx+TLCQIJyk9T9DBhKL5hJlXM1jrDwWi7a+WaOxRjWjl42trNR+uO8jkHUeYNfsFfp4fQE6tJ3MyX2HakfdAwX0fP0v/P/6DvkEiMC1Skg2lOabhsoPyQme8eMQo40KJHGOyN62ucPbD5tzIy6AsF2b83TSo8Anv+vkLwgmG6q4M/YSEBJ2YmNgtn90ZFJZX8cajtxNSm8WFoRlk5eTw8YTPue+84d09tROXr283dVb+tM0k4VSVw7NjjHVeXQ73pxuL+9BGeP1MmPpHmPF/3T1rQehWlFLrtdYJzZ3rkVEuJyK+7jZcT/8zyRMfxvuMe4lTGdQkvk1ppUTftEj2Hqgsgg3vmSzP3YtMTZbqMgiOd7pPIsfA3bvg9Pu7d76CcIIjFnpnoDUFr5yDPryFiy3PcP+l0zljaDPuoeIsU7ipp3WAr66A5Y8Z0R12cesRPgfXwNpXTDr+x1eZUrWxU+GJQaZnpyMxyCvUuNOm/tHUEB95aed/F0HoYYiF3tUohd/FT+NrreI/1hf486cbyCholARVVQbPjTO+4Z5A4luw7FHzft9SWPkUfHWLSfxpySjY84NZvNz2JWz7Al6baaJUUlaa74RcC4wAACAASURBVF+cAfFnORc2iw6ZglYTfidiLgjHgQh6ZxE6GMu5jzOueiN/qn2bP3+2idr0TbDiP0YA09dDRQH8+joUHWn9ft3N1s9h4/vm/b5l4OJhSs3u/NZY3Zs/aTi+phq++J1pKpG1E1DGlaIskL3bxJEDjLgMrpkPV8+HKz6Cafd06dcShN5ED/ut38MYdz1k7+HaNS+Qvd+Lne/vZ2jZBmqCBmHNtotcTaXJijzrX5C9FxbeA5e86WyOcKJQkm0qG9ZUGws9dooR38J0Y4Gn/GKaRDhasKWuNYubGUng6g0jL4fJt8KP/zKCnpdixjmyNzuyyqEgnKSIhd6ZKAVnP4Iefgl/sH1txFwrCr+5z4hi2HAYdC5s+RRqa2HjeyZZpn6qOxgXxUdXQm1N185fa9O+LWu3ycLUtXBoA+TsMW4SiwXOfwZmPWZ+baSuhV+eMaK/a6G5R1WpqYIYOsSEIQYPNA+u3GRz3iHogiC0GxH0zkYp1FkPY7W5oS0uzI+5H7+ydDi4mrW1g0gOO8v4klPXmKJTAAdXN7zHzoVGIB1uiq5i/0/w40PmQVNq7yi45VOz7Xeqc1yfSWb75e/hhweMsO9a1FCsQwabbXC8cb2krDy2BsyCILSKCHpX4BuBOv9p1Jn/4oLr7ua/nndQpa08nz6AP6wPRbu4w89PQvYu42M+0EjQ8+ylgh1WbVex5mWzzdgC2Bc+9/4AFptToAEC4kyESv4Bs5+6FnL3GZeTzR566EgeCh5otvuWGsE/3gbMgiA0QQS9qxh5GUy+FXeblYt++xeuCvmMvhNmsy27lr1BM2DvEjNu9FWQud2EBa54wtSucQh5WwQ9bf2xLbJWV8Dz403p2frkp8Lu/5n3hzY6j+elQNAAk53pQCmnlQ6wY4HZho8wLxcPU28FnIJeVQox49s+T0EQWkUWRbuBfiHefHb7TLTW7MssYXbyZdwdN5F5U2JMe7SN78Pyf5vB+5Y5FxAd26PxwSXGV/2br9o2mbwUs0i590dTI8dBeiKgIXiQ+eVQn9DBNGH4XNNsorzA+QAIHQYJv4WsHWCxF2TwCjbp/EED4JzH2zZHQRDahAh6N6KU4r0bJ/DE4t08+pMro8+azIQ+viYcsP8MEyq49mWzGAmtW+iVpaa+SfIyExbpqBN+NHLt7pzMHQ2PH9lu3D8DznAKutXVROWEDGl6n2EXmten15lFU3d/U19l1OWNvzT8bmnT6wVBaDficulmXKwW7pwZT7C3K08v2U2NssKpf4HoBOPGcIi5m2/rgl6c4Xz/81Ntm4Djnpk7YPf35iECphtQ0AAIHuAc6+gM1JyF7iA43j5mqPjHBaGLaVXQlVIxSqllSqntSqltSqk7mxmjlFLPKqX2KqW2KKXGds50eycerlZuP30Aq/blcOVra0jPLzMnYur5peOmG2u6trblGzl859ETTMJP5s6mYypLoKLYue9YcK0oMIlAi+414YqZ24wo+9rrVFpdnZZ5cxa6A4ePPPQoYwRB6BTaYqFXA3drrYcCk4DblFJDG405B4i3v+YBL3XoLE8CrjsllicvHcW29ALOeXoFm1PzTXngwH6m1kncqaZf5tqXGgpyfRwW+swHTHTJykZW+qaP4L/D4IWJpjAWmIeEsvu3ywtMzHjGFuNbDxter7FyCIQNBc8gM6eWqLPQRdAFoatpVdC11oe11hvs74uAHUBUo2EXAO9qwxrAXynVWllxoR5KKeaOi2bhndPwcbfxx083UV5VA/Fnm0XOPhONlfz9/bDhneZv4rDQQ4eaqJrtC5wWfXUFfHuXCRWsqYD3Ljbn8vabrE8zC7P59Q2zDRvaUNAn3gJ/2HD0YmIRo+G8J01mqCAIXcox+dCVUrHAGGBto1NRQGq9/TSair7QBvoGefH4JSNJzirh+aV74ayH4Yb/GVG/L91Yx/tXwIZ3IfHNhhcXZ5gYcc9AU3K2uswZG35oo6kxPu1uOPNfUHAQDm+CvANmrH9f0w3KIxA2fwQo85nuvuDmZwTd6tJyv04HSsH4m8x1giB0KW2OclFKeQOfA3dprQtbG9/CPeZhXDL06dPneG5xUjBlQDDnjYzgrV/2c+PUOAK8XM0JF1fjS0+aD8k/GcGuKIYpd5jzRUfAO8yIqsPlkbUTAuPgwCqz32eyaZQMJjyytsokBl3/nWnh9tWtsOs7mPonp3U+/CJj9QuCcELTJgtdKWXDiPkHWusvmhmSDtRvoBltP9YArfWrWusErXVCSEjI8cz3pOGOGfGUVNbwz2+3U1Re5TwRNx0qi42Yx0w0qfl5diu8OMPZls+RmekIRzy42sSUewWbcMLQYU7XTeRo8I8x1nfCDTD66obNJM5/Bib+vnO/sCAI7aYtUS4KeAPYobVuKRZuAfAbe7TLJKBAa324A+d50jEo3Id50/vx5cZ0rnljnfNE7DSzjUowVRlRpiAWOC10MC3dfCKNhb7nB9Nkou9k5336n24s9bHXGZeLg/gz4cIXG2aCCoLQI2iLy2UKcC2QpJTaZD92P9AHQGv9MrAQOBfYC5QCN3T8VE8+7j93CD5uLjz5w24yi8rJL61iYFgozHwQ+p5iXCJjrja+9KxdJtQwZoLzBqGDTWnbLZ8YgR99jfPc2N9AWT6c/UjXfzFBEDqFVgVda72SuvCHFsdo4LaOmpTgZGp8ME/+sJt/LNjGwqQMnrtyDOdP+5NzwFkPg3c4rHrW7Lv7Oc+FDLbXLp8G13xhfPB15wbBhS90zZcQBKFLkEzRE5zhUX542KwsTDIx5g9/t53iinqNp9184PT74PL3zH7kaOe52GmmCuKcZxuKuSAIvRIR9BMcm9XCuL4BAJwxJJQjhRV8sSGt6cABZ8D9h2DYRc5jg8+Fe3YfPRFIEIRegwh6D+CUAUG4WBQPXTCcKH8PVu3NaX6gq1fTY1JPRRBOGqTaYg/gxqlxzBoWTpS/B5P7B7FkxxFqazUWi4i1IAhOxELvAbi5WOkX4g3A5H5B5JdWsTOjqJtnJQjCiYYIeg9jcv8gABYmSZi/IAgNEUHvYUT6ezBzcCjPL9vLM0v2dPd0BEE4gRBB74G8cu04LhwdyTM/7iYpraC7pyMIwgmCCHoPxMVq4aELhhPk7cbfvkrC5HUJgnCyI4LeQ/HzsHHPWQPZnFbA8t1Z3T0dQRBOAETQezAXjYkmyt+D55fuFStdEAQR9J6Mq4uFG6fGsf5AHnsyW2hLJwjCSYMIeg9n9kjT6W/xtoxunokgCN2NCHoPJ9TXnTF9/Pl+25HunoogCN2MCHov4Oxh4SSlF3DrB+v57du/8uMOEXdBOBmRWi69gIvGRLFyTzY7M4rIKa4kJaeE0weFSq0XQTjJEEHvBYT5uvP+TRMB+HpTOnd+vImf92Zz6kDp2yoIJxPicullnDM8ghAfN97+ZX93T0UQhC5GBL2X4epi4ZqJfVm2K4vkLAllFISTCRH0XshVE/tgsyreWZXS3VMRBKELEUHvhYT4uHHB6CjeWX2Aez/fQnVNbXdPSRCELkAWRXspD80Zhp+HjTdW7qdfiBfzpvfv7ikJgtDJiIXeS/Fyc+Fv5w3hzKFhPPXDbtLzy7p7SoIgdDKtCrpS6k2lVKZSamsL509TShUopTbZXw90/DSF40EpxYPnD6Wiupb5iWndPR1BEDqZtljobwOzWhnzs9Z6tP31z/ZPS+googM8mRgXyNeb0qUioyD0cloVdK31CiC3C+YidBIXjo4iObuELdLdSBB6NR3lQ5+slNqslFqklBrW0iCl1DylVKJSKjErS5oydBXnjIjA09XKKyv2dfdUBEHoRDpC0DcAfbXWo4DngK9aGqi1flVrnaC1TggJkbT0rsLPw8a86f1YmJTB+gPyY0sQeivtFnStdaHWutj+fiFgU0oFt3tmQocyb3o/wn3dmffuemksLQi9lHYLulIqXCml7O8n2O+Z0977Ch2Lp6sL7980ETcXC3/6dFN3T0cQhE6g1cQipdRHwGlAsFIqDXgQsAForV8GLgFuUUpVA2XAFVrCKU5IBoR68/tT+/Pggm18vO4gH647SISfOw+cP4wof4/unp4gCO1EdZf2JiQk6MTExG757JOZjIJyJv37R5SCAE9XKqpqGBjuw38vG02kvweuLpJrJggnMkqp9VrrhObOyf/ek4xwP3fG9vFHa1Me4LG5I9l4MJ/TnljOgwuazR0TBKGHILVcTkJunzGA5buymD0yAqUUgV6uvLh8LwuTMvjXBcNxscpzXhB6IvI/9yRkxuAw/nnBcOxr2UwZEMy1k/pSUFbFuhQJaxSEnooIugDAtPgQXF0sPLZoJ//9YXd3T0cQhONABF0ATHXGs4aGsSWtgGd+3ENheVV3T0kQhGNEBF2o45krxvDyNWMB2JVRVHe8vKpGmmQIQg9ABF2ow2pRjIrxB2Dn4cK643NfWsVD32zvrmkJgtBGJMpFaEC4rzt+HjZ22C30AzklbDtUSFllTTfPTBCE1hALXWiAUorB4T51FvqK3aYqZnJ2CQWl4lcXhBMZEXShCUMifNl+uJBrXl/Lu6sPYDHRjWxJz6e2Vqo6CMKJigi60IQRUX6UV9Wy4WAeezKLmTMqEoD7vkhi2uPLqKyWBVJBOBERH7rQhAtGR9I3yJPhUX4s2HSI0waHkJRewL6sEgAWbT3MB2sP8tCcYQyJ8G1wbX5pJb99+1f+ecFwhkf5dcf0BeGkRSx0oQkuVgsJsYG426xcNj6GUB93LhwdxRlDwnB1sfC3r7aybn8ur65IbnLtT7uz2HAwn282H2rz5+WXVvK3r5IorqjuyK8hCCcdIuhCm/jDzHhevy6BU/oHUVRejVLwXdJh8ksrAdBak1dSyYrd2QCsTm57SfyFSRm8v+Ygv0rZAUFoFyLowjFxxpAwAP46azCV1bWc8dQK3ludwn9/2M2kf//Ikh1HUAq2phe0Odt03X4j/hkF5Z01bUE4KRAfunBMXD4+htggL6YMCMLDZmX++jQeXbgTN5uFiupaKqpruXB0JF9tOsSv+3OZaX8AtITWmrX7jWV+WARdENqFWOjCMWGzWpgaH4xSiutOieWpy0ZRVlVDfmkVd8wYwJAIX+45exDuNgvfJR1u9X5peWV1Qp5RUNbZ0xeEXo0IutAu4sN8mD0ygsHhPtx1xkAW3TmN6ABPrp7Yl683HSIl20TG1NRq1h/Io3GHrDV2X7uvu4tY6ILQTsTlIrSb/14+mppajcWRgQTcfGp/Plh7gEteXs3skRH4uLvw3NK9PD53JJeNj6kbt2DzIaL8PRgW6ct+u/gLgnB8iIUutBub1YK7zdrgWIiPGy9ePZaxffx5e1UKzy3di0XBfxbvqgtPPFxQxsq92cwdF02kv4csigpCOxFBFzqNGYPDePU3CdwxM56YQA9evmYcWUUV3PL+ekorq3ln1QG0hrljowj3c6eoopoiqcMuCMeNuFyETudPZw7kj2fEo5Ti8bkjufeLLUx69EcKy6vtWaleRPi5A3CksBwfd1s3z1gQeiatCrpS6k1gNpCptR7ezHkFPAOcC5QC12utN3T0RIWejaN/6WXjY4gL8eK1FclE+nvwt/OGAKZsL5jQxQGhPt02T0HoybTF5fI2MOso588B4u2vecBL7Z+W0JsZHxvIq79J4B9zhuFiNf8EI/09ANhxuBCtNTW1mn1ZxTz87XbpliQIbaRVC11rvUIpFXuUIRcA72oTj7ZGKeWvlIrQWrcehCwIdqIDPJgYF8hzS/fy8a+pxAZ54edh48uN6Zw7MoKxfQK6e4qCcMLTEYuiUUBqvf00+zFBaDNKKR6bO5LK6lrScstYujOzrsDX6n1trwsjCCczXRrlopSap5RKVEolZmVldeVHCz2AuGAvvr9rOj/95TT8PW1U12p83V1YvP0I176xti4JSRCE5umIKJd0IKbefrT9WBO01q8CrwIkJCRI6xuhCbHBXgD8+exBrN6XQ7C3G2+vSgGgvKqGz24+pdnrSiqqcXWxYLNKJK5w8tIR//oXAL9RhklAgfjPhfZy9cS+PH/VWKYMCAZgQKg3v6bksTW9gBeW7WXW0ytIzS2tG3/Ri79w58cbG9xDa80zS/aw+0hRl85dELqLVgVdKfURsBoYpJRKU0rdqJS6WSl1s33IQiAZ2Au8BtzaabMVTjpmDA7l1WvH8dnvJ+PlauWezzbz3x92szOjiMtfWc2BnBJySyrZfaSYhUkZLN+VWXft3sxi/rtkN++tPtDsvaskekboZbQq6FrrK7XWEVprm9Y6Wmv9htb6Za31y/bzWmt9m9a6v9Z6hNY6sfOnLZwsWC2Ks4aFE+DlyrNXjiE5uwRvdxfev3EiZVU1XPbKapbtNCLuYbNy6wcbeH7pHmpqNavsi6kbU/Oa3Leiuoap/28pv3s3kRLplCT0EsThKPQYZg4J45vbp/LxvElMjQ/m/ZsmcqSwgse/3wnAZzdP5tSBITyxeDc3v7++zlrfcbiIssoa3lmVwrnP/ExtrWZLWgFHCiv4YfsR/vXt9u78WoLQYUjqv9CjGBTuzCIdFunH6Bh/NqXmEx3gwfAoP166Zhxv/bKfh74xIh3h587hgnJ+3pPFE4t3UVReTVpeGevsTTUS+gawTlrfCb0EsdCFHs25I8IBGB7pV3fshilx3DkzHoBbTusPwP1fJlFUblwr2w8XkpiSy4BQb6bGB7M/u4TSSnG7CD0fEXShR3PO8AiUglEx/g2O33VGPJ/+fjJXT+zLkAhfyipr+MOMASgF2w8VkHggj/GxgQyL9ENr45apjyyYCj0RcbkIPZqYQE++unUK8WHeDY4rpZgQFwjA/JsnY1EKD1cr3205zOcb0ikqr2ZiXCBDI30BY7WP62vKC6Tnl3HRC79w07Q45k3v37VfSBDagVjoQo9nVIw/nq4t2yZebi54uJoGHEMifEnPL8PPw8aZQ8OI9HPHz8PG9kMFaK2prK7lro83kllUwZsrU6QwmNCjEEEXTiqGRJhF1Wsm9cHLzQWlFMMiffloXSrjHl7C1a+v4deUPC4YHUlGYTkr9mRRXFHNhoNNQx8d1NZqVu3NbpDoJAjdgQi6cFIxY3AYo2P8ue6U2LpjfzpzIL8/tR8Dw0w26kNzhvGfS0YR5OXKB2sO8vj/djL3pVV1Da8bs2pfDle9vpZpjy/jzZX7j3tuS3ceYYG9IJkgHA/iQxdOKoZG+vLVbVMaHEuIDSQhNhCtNdnFlYT4uAFw9aS+PPvjHtxcLGgNH/+ayr3nDCanuAJ/T1es9qbY+7OLAZgQG8i/F+0gITaAkdENF2nbwjNL9nAwt5TzRkSQV1rJjW//ytNXjCHOXt9GEFpDLHRBsKOUqhNzgBtOicXT1UpFdS0DQr2Zvz6V1NxSTv3Pcv782ea6cal5Zbi6WHjl2nGE+rjz27d/ZW9m8TF9ttaafVkl5JVWkZReQGJKHpvTCqR0sHBMiKALQgsEeLly58x4LhwdyT/OH0Z2cSVznl9JcUU1X2xMZ1NqPgBpeaVEB3gQ4OXKuzdOAODiF3/hf1sz2vxZGYXlFNtLECzflcm+LPNAcFj/gtAWRNAF4Sj8/tT+PH3FGKbGB3PPWQPJK63i2kl9CfZ247YPNrAlLZ+0vDKiAzwB6B/izee3nEJssBc3v7+eB7/eSm1t00rRBWVVLN+ViWn0RZ1F726zsHxXVj1Bb95vLwjNIYIuCG3kttMH8PVtU3jw/KG8cV0CADe9k8jBXGOhO+gb5MX8m0/h+lNieWf1AeavT2twn/zSSq56bQ3Xv/Ur32wxlaYdgn7JuGg2p+Wz4YCJqhFBF44FEXRBaCNKKUbF+ONitTAqxp8/nTmQzKIK8kuriLFb6A5cXSw8MHso42MDeHTRDtLzywAj5le/vpY9mcXEBXvx0IJtPLV4F7/szcbX3YVLxsWgNaTkmBDIg7mlbY6F332kiAueX0l+aWXHfnGhxyCCLgjHybSBwXXv61voDiwWxaMXjaCmRjP3xVWs25/LdW+uY09mMa9eO44Xrx6Lu83K88v2smRHJgNCvRkZ5UeglysAwyJ9qarRHMovb9N8ftyRyea0ArakFQDw0+4sFm/LqHPrCL0fEXRBOE5CfdwZEmFKBzQn6ADxYT588vvJAFz2ymqS0gt44aqxnDYolCERvvxy7wwW3D4Vf08bI6P9sVgU0+LNg2LmkDAAkptZGM0prmhybMfhQgAO5JaitebuTzcz7731/O2rrQ3GfbzuIB+uPdjsPYSejQi6ILSDUweGANAn0LPFMUMjfVl05zSunBDDU5eN5syhYQ3OD4/yY8VfTuf+c4cAMGdUJF6uVmaPjABg+a4stNZsP1TI6z8nszeziPGPLGnim3cI+sGcEg7mlpJdXEGwtxufJqbWVZPcnJrPvV8kcf+XSZz13xWslcbbvQoRdEFoB7ec1p83rksgyNvtqOMCvFz598UjuXBMVLPnfd1tuLqY/44zh4Sx5R9nMzDMh0vGRfP2qhTeWLmf135O5uHvdvDB2oPUanji+12UV9UApoG2IzLmQE4p6+2Lqr+bFkdVjWbDARNi+dzSPfh52Ph43iR8PWzc8sEGqSzZixBBF4R24Odhq3ONdCSOLNTH545kQlwgH649WGdNv7/mAN5uLmQUljP7uZU88t125q9Po1abxdiDuaUkHsjDx82FKyf2wWpRrE7OZl9WMUt2ZPLbKXFM6hfEvecMJrekUpKXehEi6IJwAmOxKM4ZHk5ydgmHCsziaFWN5vxRkTw+dyThvu68s/pAnZ98enywEfSUXMb0DcDX3cbIaD/WJOfy9aZDKAVXTogBjLvIy9XKwqTDTT43Pb+MXxt1ctqVUURuScMIGq01b/2yvy6KR+heRNAF4QRnxuDQuveT+pka75P7B3HZ+Bjev2kiG/5+JjdOjeP0QSFMGRBMaWUNu48Uc0r/IDO2XxCbU/P5aN1BJvcLItTXHQB3m5WZQ8L4flsGOcUVTHt8KSv3ZAPwn//t5JrX11JYXgUYl84lL63ioW+2UVFdQ2ahebik55fx0Dfbee7HPV329xBaRgRdEE5w+gZ50S/EC39PG/937lBGxfgzPd4ZMunt5sLfZw/lrRsmEGsv5BXi48Y1k/oCcOPUOKICPMgqqmDOqMgG9z57WDh5pVU8v2wvqbllrNiTBcDmtAIqqmvryhesTs6hqKKapTsz+duXW5nw6I9c+8ZadmWYTk/fJR2u8+cL3YcIuiD0AP7v3CE8MHsoI6L9+Pq2Kfh7ujY7bki4Lzar4t5Zg/F2M8VUg7zdeP/GidxyWn/mjG4o6FPjg7FaFO+vOQCYSJnC8qq6DNWvNqYD8MP2IwAUlVfz2fo0ogM8+HlPNt/aM12Lyo3Yt5Xqmlouf2U1i+zunoLSKhI7uFm31rruF8bJQpsEXSk1Sym1Sym1Vyl1bzPnr1dKZSmlNtlfN3X8VAXh5GXmkDAuHhvd6rhwP3c2P3gWc8c1HBsT6MlfZw1u0tnJz8PGmBh/qmpM8tGOw4VsTTeJSQl9A1idnMO2QwX8uOMIpw8Kwc0eifPvi0cAsHhbBl6uVkJ83FiYdJiktAKeXrKbgtIqftxxhJpm6tiAafm3dn8u76xOAeCln/Zx+atrOFxQxqMLd9S5dNrD/PVpjHpoMfPeTTxpmoC3KuhKKSvwAnAOMBS4Uik1tJmhn2itR9tfr3fwPAVBaCNHa8fXHI5Y+n4hXmQXV7J0h7G0H79kJL7uNq54ZQ1HCiu4fHwfLhkXzdyx0UwdEEyAp42Syhr6hXgzpX8Qa5JzeXrJbp5esoeER37gxncS+WJDWrOfucYesbNufy7ZxRVsScunplbzwNfbeHVFMh+sPciynZlHtdrfXLmfOz7a2OL5ZbsysVksLN5+hCU7mv/1UFJRzSn//pHvt7W9MuaJTFss9AnAXq11sta6EvgYuKBzpyUIQlcxZ3QkCX0DuHNmPABfbkwnOsCDfiHe3HPWQIoqqrlpahyzhofzyEUjePKyUSilGB7lB0BcsBeT+gWRXVzBsl2ZjI8NYOqAYEJ83FoUyrXJufi4uVCr4fttGXW/ChyunW+2HOK2Dzfwu3cTW8xo/TQxlQWbDzV7XmvNuv25zBoejrvNwsYWWghuTsvnUEF5gxaDzVXH7Cm0RdCjgNR6+2n2Y42Zq5TaopSar5SKae5GSql5SqlEpVRiVlbWcUxXEISOpm+QF/NvOYXTBppompySSs4bYbJUr5nUl29un1qXxVqfYZFG0PuFGEEHqNVw+4x43rphArNHRrBiT3ZdnffK6loOF5RRU2vEdvaoSPoFe/HqimQKy6vr3Dm+7i4kZ5VQWllDYXk1jyzc0eSzc0sq2WlfkF2T3NSK35dVQnZxJVMGBDEiyq+udn1jNqeaB0l6ngm7fG1FMqc9sZySip7poumoRdFvgFit9UjgB+Cd5gZprV/VWidorRNCQkI66KMFQegI/DxtXDw2ijtnxvPXWYMBU2FyRLQfFnuiU32GR5k6NnHBXvQN8iTc1x0Pm5WJcSa0ctawcCqra+sWS+/9YgtnPrWCFXuyKKqoZlK/QC5NiOGAvbKkIyrngfOHATA+NoCrJ/bh2y1NI2jW7XcmQ63al91kbuv2G5GfEBfEmD4BbEsvpKK6aRTOplRjmTvi6FfsyeJgbilvtKM3bHfSFmdbOlDf4o62H6tDa10/1ex14PH2T00QhK7mqctGt3ns9IEhXDE+hlMHhqCU4qZpcRSVV+NuswKmV2ufQE9e+Wkf4b7ufLHByMZf52/Bwx4DX1ZZw5OLdwHw57MHMXdsNEMjfUnLK+X0QaHkllby7uoDrNufy9QBwSgFaXllLNqagYfNSkJsQINM172ZRQR7u/HVpnQi/NyJDfJkTIw/r9bUsv1QIWP6BDT4DvUtdEe9HIBXftrH9VNicXexYrMqKQvQPQAACSJJREFUlGr6QDsRaYug/wrEK6XiMEJ+BXBV/QFKqQittSPdbA7Q9DeSIAi9Cl93G4/NHVm3f9O0fg3OWy2KP54Zzx8/2cw1b6wl0s8dN5uV/dklXDQmCm83F7zdXLh4bBTp+WW426wMjTRW/11nDASgtLIaV6uF/3y/ixve/hVPVytF5cYdMmNwKJP7BfGIPSrG082F85/7BU9XKzkllfzzgmEopRjb14j4wqTDdYKekl3Cx7+mklFYTpCXK5lFFaTllZFTUsm5I8JZmJTB91szeGThDu6dNZgrJvQBILOwnC82pnP9KbF1Dy4w5Rje/GU/i++ajou1+6LBWxV0rXW1Uup24HvACryptd6mlPonkKi1XgDcoZSaA1QDucD1nThnQRB6CHNGRfHRulRcrRYeuWg43245zH++38XFY53LcI9dPJKWDGBPVxfG2cMnB4X5MC42gMHhPvQL9mZElB/77KWFNxzMo6pGU1ZVQ3VtLbFBnlxpF+EwX/e6ImdXTOjDofwyfv/eesqragjycuWy8TG8tHwfS3aYBdlrJvblp11ZPLF4F/mlVSzcmsEVE/pQW6v5w0cbWbs/lz1Hinni0pEopait1bz2czIHckrZfaS47qHUmPKqGh5btJPfTe9HlH/z5ZbbS5vim7TWC4GFjY49UO/9fcB9HTs1QRB6OlaL4lN7PXiA306JIy7Yi6kDnJmuzfnn63P2sDC2phfw0jVj6Rfi3eDcsEhfXF0srD+Qx6H8coK93fjy1lNwdbFgq2cp/3XWYBYlHeb1n5PJLKzAz8PGj3efSoSfB6v35fDS8n0s3mYEfUS0HxP7BdX5/tcm51BeVcNn69NYuz+XSf0C+XxDGhPjArlsfAxrknPq1gE2pua1KOifb0jj7VUphPm6c8tp/Y/hr9h2JFNUEIQuw8PVyrkjIo7JJ33dKbGs+78zmog5gJuLlZFRfvy8J5ulOzOZNTyMmEBPwuz1ahyE+LgxuX8wq/flsDE1nykDgonwM1ayoznJ6uQc+gZ54uNuq3vg9A/xoqK6lsSUPD5Yc4BR0X58eNMkJsYF8q/vtpNRUM4Haw/i6+5CgKeNjQebj6YxRcxSAFOTvrMQQRcE4YRGKYWHq7XF8+P6BrAzo4iqmlquGN+nxXET4wJJySklt6SScX2di6Phfk7xv8rupjlzaBgxgR48NnckNqviuaV72JlRxNxx0Vgsiv83dyRVNbXc+sF6Fm09zJUT+zCub0CDeHaArKIKvtiQxi3vb2BvZjF+Hja2pHWeoB9bSpkgCMIJxoS4QF5Zkcy95wyuS3Zqjon2SpUAY+tFu9isFvoGeeJhs/I7+8JuTKAnP/9lBgBXT+zL26tSsFkVs0eaWjixwV7cc9YgHv5uB24uFm6a2o9PE1NZsiOTnOIKSipqeH/tAd5bfYCyqhr8PGzcelp/fD1sPLZoJ1lFFYT4HL0pyvEggi4IQo9mxuBQvrl9al1cfEsMjfDFy9WKRSniQxu6b/5353RcXSzN+vMfmD2UAE9XXKyqroE3wA1T4tiUms+wSD9CfNyYOSSUJxfv4u7PNrMmOYeqGs3skRHMm96PweG+WC2qLj5+S1p+pzRGEUEXBKFH40h+ag0Xq4Wzh4eDbroQezSXjsWiuPOM+CbHrRbF81eNrdsfHO7LdafE8tYvKfQJ9OSjeZOaRLMMj/LFokx5YhF0QRCEdnAsiVPHw91nDcLVxcKV4/s0G5ro6erC/2/vfkLjqMMwjn8fiu1BC1oLEmrQVHrJqYYgPZQe1cZD9NaTPQheFPTgIZJLrwp6EERQLFQRe1GxF8E/CJ6sppKmqSU21YqG2AiCelLR18P8gku6s7HbbX4zv30+sOzszGbzPnk3b3Zmd7OzD42zf3TzP0D9UESef0QzOTkZc3NzWb63mVlbSToTEZPdtvlVLmZmhfBANzMrhAe6mVkhPNDNzArhgW5mVggPdDOzQnigm5kVwgPdzKwQ2d5YJOln4Ps+v3w3cPUHCZZpWLIOS05w1hJtZc67IqLrhzJnG+jXQ9Jc3TulSjMsWYclJzhriZqS04dczMwK4YFuZlaItg70V3MXsIWGJeuw5ARnLVEjcrbyGLqZmV2trY/QzcxsAw90M7NCtG6gS3pQ0pKkZUkzuesZJEmXJZ2TNC9pLq3bJekjSRfT+W2b3U4TSTouaU3SYse6rtlUeSn1eEHSRP0tN09N1mOSVlJv5yVNdWx7NmVdkvRAnqqvnaRRSZ9K+lrSeUlPpfVF9bVHzub1NCJacwK2AZeAvcB24CwwnruuAea7DOzesO55YCYtzwDP5a6zz2yHgAlgcbNswBTwASDgAHA6d/0DyHoMeKbLdcfT/XgHMJbu39tyZ/ifOUeAibS8E/gm5Smqrz1yNq6nbXuEfh+wHBHfRsSfwElgOnNNN9o0cCItnwAezlhL3yLiM+CXDavrsk0Db0Tlc+BWSSNbU+n1q8laZxo4GRF/RMR3wDLV/bzxImI1Ir5Ky78DF4A9FNbXHjnrZOtp2wb6HuCHjss/0vsH2zYBfCjpjKTH07o7ImI1Lf8EDP6jwvOpy1Zqn59MhxqOdxw6KyKrpLuBe4HTFNzXDTmhYT1t20Av3cGImAAOA09IOtS5Mar9uSJfZ1pytuQV4B5gP7AKvJC3nMGRdAvwDvB0RPzWua2kvnbJ2bietm2grwCjHZfvTOuKEBEr6XwNeI9qN+3K+m5pOl/LV+HA1WUrrs8RcSUi/o6If4DX+G8XvNVZJd1ENeTeioh30+ri+totZxN72raB/iWwT9KYpO3AEeBU5poGQtLNknauLwP3A4tU+Y6mqx0F3s9T4Q1Rl+0U8Gh6VcQB4NeOXfhW2nCs+BGq3kKV9YikHZLGgH3AF1tdXz8kCXgduBARL3ZsKqqvdTkb2dPczyD38YzzFNWzzJeA2dz1DDDXXqpnxs8C59ezAbcDnwAXgY+BXblr7TPf21S7pX9RHVN8rC4b1asgXk49PgdM5q5/AFnfTFkWqH7hRzquP5uyLgGHc9d/DTkPUh1OWQDm02mqtL72yNm4nvqt/2ZmhWjbIRczM6vhgW5mVggPdDOzQnigm5kVwgPdzKwQHuhmZoXwQDczK8S/n9k04qYeUtoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB0um_6DuDZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecbf8a8-366b-4e47-d9ad-2f974fb65b6d"
      },
      "source": [
        "# #Testing the model\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "scores,acc = saved_model.evaluate(X_test, y_test,verbose=0)\n",
        "model.summary()\n",
        "print(\"Accuracy on the test set: {}%\".format(acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 64)                26880     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 27,530\n",
            "Trainable params: 27,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy on the test set: 21.50000035762787%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJrU6zZcU6Ot"
      },
      "source": [
        "# Testing\n",
        "\n",
        "---\n",
        "Running tests on the videos in the test set and predicting the output and their probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOSOQWRTlJCa",
        "outputId": "aab9232f-88fc-4c18-b5c1-0f0546529a47"
      },
      "source": [
        "speakers=os.listdir(test_set)\n",
        "for s in speakers:\n",
        "    word_list = os.listdir(os.path.join(test_set,s))\n",
        "    for word in word_list:\n",
        "        repetition = os.listdir(os.path.join(os.path.join(test_set,s),word))\n",
        "        for rep in repetition:\n",
        "            test_video_path = os.path.join(os.path.join(os.path.join(test_set,s),word),rep)\n",
        "            frame_list = os.listdir(test_video_path)\n",
        "            frame_list.sort(key=numericalSort)\n",
        "            \n",
        "            test,bool_flag = preprocessing(test_video_path, frame_list) \n",
        "            test = test.reshape((1,25,20))\n",
        "            y = int(np.argmax(model.predict(test), axis=-1))\n",
        "            y2 = model.predict_proba(test)\n",
        "            temp = list(class_dict.keys())\n",
        "            print(\"The predicted word for {} is {} \".format(actual_class_dict[word],actual_class_dict[temp[y]]))\n",
        "            print(y2)\n",
        "            print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The predicted word for Connection is Connection \n",
            "[[3.8233811e-06 4.6588422e-04 9.8258787e-01 8.6658629e-06 2.4701946e-04\n",
            "  1.0182909e-04 1.2560005e-07 5.1781649e-07 5.3466326e-08 1.6584208e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.5236832e-04 9.9178892e-01 5.4149909e-06 3.1156321e-06 1.9710892e-06\n",
            "  5.3037624e-03 2.0204898e-06 2.5505738e-03 3.4985121e-06 1.8836035e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.9453294e-01 8.5142870e-05 1.7602191e-05 1.1382428e-04 6.7341223e-04\n",
            "  4.3244790e-03 9.5279502e-05 2.0911053e-05 1.8575730e-06 1.3461393e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[6.4947279e-05 7.5270563e-09 2.0318645e-07 1.7423552e-05 9.9987376e-01\n",
            "  1.0356230e-06 2.6550913e-06 2.3822951e-08 3.9832543e-05 4.0602963e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[2.3765751e-06 3.2360512e-07 5.6855079e-06 9.9978060e-01 2.9903875e-05\n",
            "  5.9629942e-06 8.4309559e-06 2.3833195e-07 1.6650054e-04 3.2377345e-10]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[6.3491161e-06 3.3473589e-07 9.8153862e-08 4.1162567e-03 1.9213618e-05\n",
            "  1.9709542e-03 3.1122840e-03 9.5286669e-04 9.8982167e-01 2.8687193e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[1.0867017e-04 5.0109061e-03 2.0280818e-04 3.5056198e-07 8.0537153e-05\n",
            "  1.2238733e-03 1.6979917e-05 6.3710281e-04 1.9126630e-06 9.9271691e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[2.2443957e-03 5.2984818e-05 1.2514723e-06 3.8350883e-04 3.6387155e-05\n",
            "  9.9713409e-01 9.5053772e-05 2.1868871e-05 2.4759018e-05 5.6904100e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Previous \n",
            "[[8.9056380e-03 2.0661439e-04 2.9137065e-05 9.0468824e-03 5.1817653e-05\n",
            "  8.9762008e-01 3.8650796e-02 1.6288543e-02 2.9154263e-02 4.6249428e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Stop \n",
            "[[1.7365786e-04 7.9120946e-06 1.0885358e-05 3.8579616e-03 6.3493513e-07\n",
            "  5.0300945e-02 2.8437603e-01 6.6121304e-01 4.7986097e-05 1.0949044e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Start \n",
            "[[3.0547049e-02 1.4266832e-06 7.3154445e-04 8.1579782e-02 4.5627398e-06\n",
            "  2.0371541e-02 8.5268945e-01 1.3596575e-02 4.5229515e-04 2.5709054e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[3.6770835e-08 9.9924672e-01 2.5533719e-04 4.8560815e-07 1.0956004e-06\n",
            "  1.8993190e-06 1.7527918e-07 2.9500570e-05 8.8530058e-08 4.6454748e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[1.3273880e-07 2.2221704e-05 9.9915755e-01 7.6602364e-04 1.9704959e-05\n",
            "  7.3041593e-07 1.3759958e-06 3.0358063e-07 2.0837956e-06 2.9724246e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[1.7934954e-06 1.8310354e-07 6.7834469e-04 9.9888390e-01 2.1669850e-05\n",
            "  7.0496772e-06 1.6934334e-04 2.4814378e-06 2.3517072e-04 2.0470601e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Connection \n",
            "[[1.6773846e-02 4.3870885e-05 6.0947514e-01 1.3471271e-01 2.2281054e-01\n",
            "  2.0119785e-03 1.0032487e-02 7.8757534e-05 3.5502529e-03 5.1036756e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.9884982e-07 2.7104578e-04 9.3167546e-05 7.8084367e-06 1.4053946e-03\n",
            "  1.7825243e-05 1.0260322e-04 9.9431854e-01 5.8291422e-04 3.2004775e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[2.8380015e-08 7.6831115e-05 8.0497048e-05 2.8926832e-09 2.2297068e-06\n",
            "  5.3230242e-06 2.6571121e-07 1.1804787e-03 6.9731016e-08 9.9865425e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[6.7600593e-07 1.0063333e-07 7.4121838e-09 1.0439824e-06 6.3110936e-05\n",
            "  1.0082801e-03 9.1933555e-07 2.2134234e-05 9.9890351e-01 2.9256503e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Begin \n",
            "[[7.7250302e-01 4.0841852e-03 2.1552020e-03 3.0459450e-03 5.8555208e-02\n",
            "  1.2753972e-01 9.6801350e-06 1.1758500e-04 1.0746227e-03 3.0914858e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[2.10770886e-05 9.82900929e-07 3.56523873e-04 1.64623819e-02\n",
            "  6.91630412e-05 1.66712653e-05 8.34945381e-01 1.47994712e-01\n",
            "  1.04545274e-04 2.85803544e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.3749636e-01 4.4480709e-07 8.5859254e-05 3.9226061e-04 6.1377350e-02\n",
            "  2.1783767e-04 3.5877738e-04 1.6166305e-06 1.8240351e-05 5.1145202e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[1.6552652e-06 1.4262680e-06 9.9490404e-01 5.3103358e-05 4.4248765e-03\n",
            "  5.6411631e-07 2.1366292e-04 9.7791030e-07 2.1579690e-06 3.9740081e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.8230448e-09 9.9969971e-01 1.5928459e-05 6.5265446e-09 1.4150880e-08\n",
            "  1.9086698e-07 1.1469505e-08 1.6089789e-05 3.8588337e-09 2.6802867e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[4.3734867e-06 9.5029014e-07 2.5723182e-02 9.6057737e-01 1.6421484e-04\n",
            "  6.8944109e-06 1.3443566e-02 3.9865158e-06 7.5236327e-05 1.3234509e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Start \n",
            "[[2.1543369e-01 2.7987566e-08 1.4136490e-05 5.6461603e-03 6.2942229e-02\n",
            "  2.1956312e-05 7.1256399e-01 1.1282363e-04 3.2496026e-03 1.5449004e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[7.81141864e-07 5.96775562e-09 4.92331398e-10 1.54187674e-07\n",
            "  1.99632564e-06 1.21040444e-04 2.50903649e-05 2.78104817e-05\n",
            "  9.99823034e-01 6.14077535e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[1.15162329e-05 1.02433104e-10 6.23865617e-07 7.19339084e-07\n",
            "  7.44097561e-05 7.07534014e-07 9.99838591e-01 6.98321383e-05\n",
            "  1.86280465e-06 1.66478276e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[4.3783290e-03 1.7985374e-07 2.5775037e-06 6.9275127e-05 1.4228216e-01\n",
            "  6.4888948e-01 3.2417458e-03 5.9317483e-04 1.9969350e-01 8.4958726e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[7.2402548e-07 2.6564936e-07 2.4655621e-04 7.8550594e-10 4.0178133e-05\n",
            "  2.5421139e-07 5.1801879e-07 7.1671693e-06 6.2159287e-09 9.9970430e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Start \n",
            "[[3.3472603e-05 3.3904945e-07 6.8633958e-06 3.3629584e-04 7.7822653e-05\n",
            "  3.4449663e-06 8.8222563e-01 1.1655528e-01 7.0811383e-04 5.2800049e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[6.5632548e-06 1.3056663e-02 9.8574591e-01 9.9141384e-05 4.9158221e-05\n",
            "  1.6090231e-05 4.7958442e-06 1.0229632e-05 2.5830602e-07 1.0112044e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[2.8375865e-05 9.7258329e-01 1.2626990e-03 4.6330304e-05 1.5153443e-04\n",
            "  1.8737743e-02 6.0320081e-06 1.9856710e-03 1.9056486e-05 5.1791570e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.9823821e-01 6.6096803e-08 1.3804461e-06 2.6750233e-04 1.3730363e-03\n",
            "  1.8614795e-05 9.3336552e-05 2.8536871e-07 6.2108666e-06 1.4636378e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[1.6400170e-04 8.0213719e-04 2.3738802e-03 6.6918695e-01 9.3987689e-04\n",
            "  1.1694513e-01 4.0378789e-03 3.6934889e-03 2.0185429e-01 2.3589862e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Begin \n",
            "[[9.4542176e-01 2.0647592e-05 1.6019390e-04 1.5557563e-02 3.7244227e-02\n",
            "  4.0672900e-04 1.0432643e-03 1.0874739e-05 8.3395222e-05 5.1419775e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[4.2292989e-08 5.7447993e-05 1.8354565e-05 3.1773209e-09 1.2917965e-07\n",
            "  7.5622456e-06 4.6567590e-07 3.1563377e-03 4.0616719e-08 9.9675971e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[1.1709092e-02 2.2528588e-03 7.1547952e-06 1.1767251e-03 3.2667584e-05\n",
            "  9.6158785e-01 1.3403605e-03 2.1712976e-02 1.2734036e-04 5.2985037e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[4.8748578e-05 5.2773954e-09 2.1556975e-06 3.8585908e-04 9.0205089e-07\n",
            "  4.4797378e-04 9.9316883e-01 5.9443261e-03 1.0840221e-06 2.5628572e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Start \n",
            "[[1.7927142e-02 6.3015710e-07 3.3586497e-05 8.8851430e-02 5.7233637e-03\n",
            "  3.1840723e-02 7.9241771e-01 4.1500796e-03 5.9052862e-02 2.5473048e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[2.0937085e-05 1.9987672e-06 3.6745253e-06 1.0627944e-06 5.2868923e-08\n",
            "  6.4875098e-04 8.7529363e-04 9.8415953e-01 1.1845578e-06 1.4287442e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.99839067e-01 1.31050939e-07 2.40378768e-06 1.01745994e-04\n",
            "  4.28746534e-05 6.17193336e-06 6.85644500e-06 7.73558213e-08\n",
            "  3.18815808e-07 2.46180917e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.6835740e-08 9.9972850e-01 2.1420130e-05 2.2848998e-07 2.1975929e-07\n",
            "  3.0810015e-06 7.4745522e-08 2.1106382e-04 1.9762771e-07 3.5211771e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[6.6946126e-07 6.5880136e-05 9.9119228e-01 6.7995521e-03 3.0316151e-05\n",
            "  1.1853845e-06 1.0123287e-03 8.4405096e-04 4.1048423e-07 5.3348969e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[1.1184845e-06 1.8708995e-07 1.8592308e-04 9.9978930e-01 5.4960697e-07\n",
            "  9.3003127e-06 4.4829153e-06 8.1353318e-07 8.1779008e-06 9.6928385e-09]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[1.6218697e-04 3.3937924e-09 2.4382743e-08 3.0718573e-05 9.9814212e-01\n",
            "  5.9402777e-07 3.9988572e-05 2.4836243e-07 1.6241017e-03 2.5575909e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.55099169e-08 1.10088506e-04 5.16080036e-06 2.15650871e-07\n",
            "  2.44997636e-06 3.83408769e-06 1.48381559e-05 9.83702898e-01\n",
            "  4.81463985e-06 1.61556657e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[6.5891619e-08 6.5502390e-05 1.8868539e-05 1.2203728e-08 1.4967287e-06\n",
            "  6.0577554e-07 6.8360879e-07 9.0026166e-03 1.0591004e-07 9.9090999e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[1.9079611e-07 5.5274018e-07 6.0472956e-07 7.1441947e-04 3.1981270e-07\n",
            "  9.9916756e-01 1.3139032e-06 2.2989991e-05 9.1844529e-05 2.7271832e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[1.03665393e-07 3.03348568e-09 1.71438541e-09 4.22819085e-07\n",
            "  5.17682311e-05 1.00108955e-05 5.22776782e-06 4.45767910e-06\n",
            "  9.99927998e-01 2.74372809e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[2.1518237e-05 3.5377412e-10 2.7340977e-05 1.6707865e-05 1.4285584e-07\n",
            "  1.7108656e-06 9.9973768e-01 1.9346367e-04 7.0586836e-08 1.3530254e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[1.6796207e-08 6.4108212e-06 9.9997914e-01 2.9949902e-06 3.3373126e-06\n",
            "  1.6777539e-08 9.5134673e-08 2.0393422e-08 8.6939800e-10 8.0153832e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[3.2102616e-08 9.9833566e-01 8.8065923e-07 6.8612728e-08 2.8309273e-07\n",
            "  2.0478587e-05 1.4163150e-07 1.5771955e-03 4.5653042e-06 6.0730639e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Next \n",
            "[[1.3788633e-01 1.6330139e-08 3.0661527e-06 3.6918439e-04 8.6154473e-01\n",
            "  6.7537694e-05 6.7552828e-05 6.9455990e-07 5.1469913e-05 9.3395574e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Previous \n",
            "[[1.2249321e-06 1.3521117e-05 2.4772622e-04 8.1252062e-04 1.4254620e-04\n",
            "  9.9859434e-01 3.6574829e-07 7.2104644e-06 3.3262293e-06 1.7716776e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Next \n",
            "[[3.6080714e-04 1.7498309e-07 4.3626364e-06 2.3992676e-02 9.6692145e-01\n",
            "  8.8008972e-05 5.1330528e-05 1.2628193e-06 8.5788425e-03 1.1636888e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[3.4400051e-05 1.0631317e-03 1.4878875e-03 2.5548509e-04 8.6502219e-04\n",
            "  9.5733392e-01 2.1833589e-06 1.2864349e-04 2.7329024e-06 3.8826548e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[2.6483534e-08 5.6301721e-04 6.8403620e-05 3.9544563e-09 3.5022885e-07\n",
            "  4.0686504e-07 4.7991330e-07 5.9456658e-04 1.5722190e-08 9.9877268e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[3.0726055e-06 1.2085876e-09 3.6260601e-06 7.7773075e-06 3.2692838e-06\n",
            "  1.0128475e-06 9.9948883e-01 4.8530332e-04 2.9346952e-06 4.2203587e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[1.7839751e-07 8.2725489e-09 8.4535845e-10 3.2537326e-07 2.1971445e-04\n",
            "  1.2426339e-04 1.0682364e-06 3.6293532e-06 9.9965072e-01 1.2034243e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Previous \n",
            "[[7.5270399e-04 4.0062379e-02 4.4757885e-06 3.3081410e-04 1.7459125e-04\n",
            "  5.1337713e-01 5.5809366e-04 4.2295554e-01 1.6575314e-02 5.2089896e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[7.2738413e-07 6.4151982e-06 9.9940777e-01 3.5144226e-04 1.4647491e-04\n",
            "  8.2387705e-06 4.0390059e-06 1.0450007e-06 4.4626208e-07 7.3338204e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[9.3866976e-09 9.9983048e-01 1.2764527e-05 1.1750500e-07 2.4552023e-07\n",
            "  2.1057062e-06 1.4627709e-07 9.7482123e-05 2.2008331e-07 5.6390032e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Previous \n",
            "[[3.3191693e-05 9.5113473e-06 1.2672289e-05 2.5685125e-03 1.0700359e-04\n",
            "  9.8610467e-01 5.6854926e-05 9.8918455e-05 1.1008258e-02 4.3827575e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[1.9234091e-03 4.3696291e-06 6.2090447e-03 9.9124122e-01 3.6429765e-04\n",
            "  2.8279750e-05 1.8469084e-04 4.7971560e-07 4.4098117e-05 8.3000025e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Begin \n",
            "[[9.0272379e-01 4.9982358e-08 5.7989732e-06 5.1964633e-04 9.6275836e-02\n",
            "  8.2135903e-06 4.4606740e-04 6.9241622e-07 1.3713052e-05 6.1563019e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[2.4722128e-06 9.2721648e-06 7.4593555e-07 3.6010046e-05 1.0870453e-04\n",
            "  9.9947149e-01 2.0583393e-06 3.1459542e-05 3.3357422e-04 4.2564211e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[3.2819088e-07 2.1650171e-01 1.9341994e-03 7.4602561e-08 2.0450338e-05\n",
            "  2.1615666e-05 8.7991839e-07 2.8160731e-03 6.0052901e-07 7.7870411e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[3.6069257e-05 5.0956282e-06 1.2869754e-06 8.7449874e-04 2.1801672e-03\n",
            "  4.6324267e-04 1.2248989e-02 1.0263012e-01 8.8155854e-01 1.9484614e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Begin \n",
            "[[8.1645703e-01 7.4878583e-09 6.9434418e-07 4.1022412e-03 1.7052700e-04\n",
            "  5.8170030e-05 1.7906570e-01 1.4745297e-05 1.3071080e-04 2.1852321e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[7.0275470e-05 1.0186780e-03 2.8808520e-04 2.8886443e-05 4.0889303e-03\n",
            "  6.1542070e-03 9.7592780e-03 8.5472536e-01 2.4182932e-03 1.2144801e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.99701560e-01 5.13114600e-08 3.10275868e-06 2.03848671e-04\n",
            "  6.81984311e-05 4.97653718e-06 1.79431227e-05 4.62963108e-08\n",
            "  1.12389635e-07 1.06493445e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.5430172e-07 9.9875879e-01 2.2437645e-05 4.5822279e-07 9.1347711e-06\n",
            "  5.7177323e-05 9.2806715e-07 9.5497514e-04 1.2089828e-05 1.8391036e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[8.3394159e-05 5.7075635e-05 9.5093733e-01 4.8609674e-02 1.7147636e-04\n",
            "  1.1433125e-05 1.1540530e-04 8.0833240e-07 4.7153139e-06 8.7755907e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[2.2921035e-04 6.2347375e-08 2.6640489e-06 9.9392772e-01 1.6867017e-04\n",
            "  4.1699011e-05 1.3315058e-03 3.6965039e-06 4.2949100e-03 1.9689537e-09]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[3.2473793e-03 9.7920214e-08 9.5761422e-08 5.3633372e-05 9.9649626e-01\n",
            "  1.9927016e-05 7.0677794e-05 1.1673486e-06 1.1022320e-04 4.7820839e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.9650868e-06 4.2110214e-06 1.5440972e-07 1.7758380e-06 3.9227121e-08\n",
            "  1.7290669e-03 1.2208683e-04 9.9782264e-01 4.8911283e-05 2.6908497e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[8.6922542e-04 1.6095966e-07 5.1519792e-06 7.5489510e-04 3.8675548e-06\n",
            "  4.4787204e-01 5.4117167e-01 8.4648039e-03 6.7085371e-04 1.8726778e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[1.34590110e-07 2.09076738e-04 5.70142365e-05 1.68024050e-09\n",
            "  3.49453245e-07 2.14300780e-06 5.29398889e-08 1.87392114e-04\n",
            "  1.42513485e-08 9.99543846e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[6.1949873e-07 6.4734742e-08 2.8137505e-08 8.2182132e-06 3.3235062e-06\n",
            "  9.9997258e-01 2.3546036e-07 3.3444912e-06 1.1135531e-05 4.4937602e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[8.3893002e-07 2.3670839e-06 2.0418687e-09 1.3676813e-06 2.8013463e-05\n",
            "  7.8179929e-03 6.3014006e-05 6.2469576e-02 9.2961586e-01 9.6547092e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.5751566e-01 6.7838726e-09 7.4229497e-06 1.4626137e-04 1.5192186e-03\n",
            "  2.1773955e-04 4.0472221e-02 1.0079424e-05 9.3513139e-05 1.7875145e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.8767746e-07 9.9857199e-01 3.4245149e-05 2.5456623e-07 4.7881349e-07\n",
            "  7.8175159e-05 1.6493721e-07 8.8785565e-04 4.7966358e-07 4.2603334e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Web \n",
            "[[1.20492994e-04 2.43304949e-05 1.34687111e-01 4.75192755e-05\n",
            "  4.58538858e-03 3.17275859e-02 8.63058306e-03 1.10976202e-02\n",
            "  1.44552163e-04 8.08934808e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[3.1549912e-02 4.0674558e-06 8.7437074e-04 2.5156127e-02 9.3008494e-01\n",
            "  1.9500799e-03 3.5491333e-04 9.1233596e-06 9.9704685e-03 4.6115747e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[1.5677627e-02 1.7123746e-07 2.9814888e-03 9.8013455e-01 8.0272852e-04\n",
            "  1.3583436e-05 3.7007636e-04 2.0728963e-07 1.9142402e-05 4.0072666e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[3.8226329e-07 5.3579585e-09 9.6255350e-09 7.5192188e-06 4.5044246e-05\n",
            "  5.0863314e-06 2.3845716e-05 1.2863664e-05 9.9990523e-01 2.1368383e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.4647561e-07 5.8290776e-04 9.1091541e-05 9.3886513e-07 3.7017057e-07\n",
            "  1.5857333e-05 2.4616139e-04 9.7999018e-01 7.4811174e-07 1.9071659e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[1.8673034e-04 5.0760939e-04 1.3688336e-02 4.9808051e-04 2.3633760e-04\n",
            "  6.2881608e-04 1.0491262e-01 3.1668714e-01 6.0491540e-05 5.6259388e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Stop \n",
            "[[3.3997385e-05 1.5673061e-06 2.3155201e-03 5.9161452e-03 4.6010450e-06\n",
            "  8.7345694e-04 4.9272093e-01 4.9797800e-01 8.0295167e-06 1.4778892e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[8.5072947e-04 1.2407682e-02 1.2823904e-03 1.0678519e-03 3.2205167e-04\n",
            "  9.7185224e-01 5.2000902e-04 9.4235484e-03 1.4859895e-03 7.8749913e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.8220569e-01 5.4165266e-05 3.3752403e-05 1.9721421e-03 1.5361797e-03\n",
            "  6.6401390e-03 4.8502057e-05 1.5009691e-04 7.0361421e-03 3.2322574e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[8.1787931e-07 3.9371889e-04 9.9860567e-01 1.1448550e-05 6.2658108e-07\n",
            "  8.8579827e-06 6.4917726e-06 2.6748332e-05 1.8732925e-08 9.4556308e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.13577364e-07 9.99534845e-01 3.07041523e-06 6.87277463e-07\n",
            "  3.37503707e-07 9.90555855e-05 1.77454822e-07 3.43420572e-04\n",
            "  1.04789251e-05 7.83403175e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[5.82509451e-02 2.65960875e-06 7.98603927e-04 9.35261905e-01\n",
            "  1.33300155e-05 5.03319548e-04 3.14483256e-03 6.37191915e-05\n",
            "  1.95559603e-03 5.09173105e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Stop \n",
            "[[5.9932809e-06 7.5661733e-06 5.3690462e-07 6.4824977e-05 2.1340671e-05\n",
            "  6.2139700e-03 2.7095741e-03 9.7666943e-01 1.4207732e-02 9.8976649e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.2468805e-05 3.5774782e-03 1.2459313e-06 1.3365140e-05 5.3656622e-06\n",
            "  1.0379441e-03 4.2042611e-04 9.9235570e-01 1.2488412e-03 1.3271950e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[9.3591316e-03 5.9113630e-05 2.9874038e-06 1.2811650e-04 9.8059994e-01\n",
            "  5.6838673e-03 1.0889902e-05 4.6529185e-05 3.7922454e-03 3.1718062e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[2.4415915e-05 1.2771148e-05 1.5039360e-08 5.7054622e-05 1.5720583e-06\n",
            "  9.9665725e-01 7.0099049e-05 1.4234026e-03 1.7520167e-03 1.3463759e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[2.2061772e-07 6.6383276e-04 6.1346269e-05 7.6437212e-09 1.2447019e-06\n",
            "  2.5625368e-07 2.2231075e-07 2.0409615e-03 1.0169530e-07 9.9723178e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[3.3813445e-03 3.0202298e-07 8.3283885e-06 2.6331225e-04 2.4153431e-05\n",
            "  1.5733854e-03 9.6707672e-01 2.5091782e-02 2.0180640e-03 5.6264986e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.5171142e-01 1.9013360e-09 1.7799869e-06 4.4059029e-04 4.5218468e-02\n",
            "  3.3312099e-05 2.5007711e-03 1.5095031e-06 9.0797941e-05 1.4691399e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Stop \n",
            "[[1.2465352e-07 1.1789108e-02 9.4408460e-06 1.3723433e-06 8.4853973e-06\n",
            "  2.4435552e-05 1.0534894e-04 9.6635926e-01 6.8693022e-05 2.1633811e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[3.5826406e-03 8.2428116e-05 9.6479237e-01 6.0448900e-05 6.6845684e-04\n",
            "  8.3043480e-05 3.9781912e-06 5.7873928e-07 6.7304870e-07 3.0725377e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[2.05575975e-06 1.15560916e-07 2.01536136e-06 9.98835027e-01\n",
            "  1.72293934e-04 9.39701276e-05 1.49051166e-05 6.13744930e-07\n",
            "  8.79130617e-04 1.85273319e-09]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[4.7523078e-01 2.2732632e-08 6.4933702e-06 2.0761600e-04 5.0520700e-01\n",
            "  1.7977394e-05 1.4994088e-02 2.6119014e-05 4.1822661e-03 1.2763251e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[2.5321660e-07 1.6734519e-09 6.7847267e-10 7.3741586e-07 1.9949230e-06\n",
            "  1.6130802e-05 5.4878310e-06 3.5011824e-06 9.9997187e-01 9.3366319e-09]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[1.9768826e-05 8.1881035e-06 6.1191781e-07 1.8281353e-04 2.1595183e-06\n",
            "  9.9864417e-01 1.9531302e-05 6.8365515e-04 4.2265395e-04 1.6508715e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.6589253e-08 3.3909921e-06 5.7124765e-08 2.9055523e-06 4.4401136e-09\n",
            "  8.0287709e-06 3.1507303e-04 9.9964905e-01 2.1165302e-05 2.4302196e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[6.1184224e-03 1.9550730e-06 6.5375552e-02 1.6281037e-05 1.7693110e-03\n",
            "  5.5294950e-06 8.0964267e-03 7.8173610e-04 1.0468729e-05 9.1782427e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[8.9058349e-06 1.1160834e-09 1.2604740e-07 1.0757829e-04 9.7563134e-07\n",
            "  3.8685016e-06 9.9906701e-01 7.6113921e-04 5.0263599e-05 5.5455430e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[4.2987090e-06 1.8457731e-05 9.9983788e-01 2.6069918e-05 1.0926133e-06\n",
            "  3.2179648e-07 1.1733320e-05 3.4587723e-07 4.6884892e-08 9.9844852e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.6812999e-01 9.7390461e-05 1.7646994e-04 3.4108508e-04 2.9782090e-02\n",
            "  2.8976076e-04 1.5312664e-05 1.8017786e-06 2.3750781e-05 1.1423400e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[7.6293611e-09 9.9993849e-01 5.5064625e-06 8.8709848e-09 1.4782838e-08\n",
            "  2.2458065e-07 1.0226988e-08 2.3012821e-05 6.2978557e-08 3.2759883e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[1.0161126e-03 3.2165559e-08 1.7146688e-08 5.3608095e-05 9.9773407e-01\n",
            "  1.5670586e-05 8.2315921e-05 1.5083934e-06 1.0966788e-03 8.6298300e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Connection \n",
            "[[9.6515849e-02 3.1967997e-03 6.2774479e-01 2.7136195e-01 2.2275570e-04\n",
            "  3.1697747e-04 4.0967841e-04 1.1519679e-05 1.4148840e-05 2.0558827e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[1.5220359e-04 2.9844210e-10 1.4376715e-06 7.6523793e-05 1.5443939e-04\n",
            "  5.9309923e-06 9.9938250e-01 1.0582549e-05 2.1613335e-04 2.6118948e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[3.8636369e-07 4.2257917e-09 6.3697531e-10 1.3189157e-06 1.2671199e-05\n",
            "  3.3783130e-05 6.8994555e-06 6.5141198e-06 9.9993837e-01 1.3100039e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[6.3163480e-07 7.1539478e-07 1.7804629e-07 1.5558121e-06 1.8647128e-04\n",
            "  9.9975139e-01 4.8869570e-08 3.4662708e-06 2.2777507e-05 3.2796575e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[4.1836111e-06 1.0165468e-06 3.4885847e-03 7.1004846e-09 5.0568359e-04\n",
            "  4.4600336e-07 6.9101151e-07 1.7938626e-06 4.1011628e-08 9.9599755e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.4228516e-08 2.5682630e-06 7.9807023e-08 1.9696870e-06 7.3398194e-09\n",
            "  4.0697505e-06 2.7717423e-04 9.9970847e-01 3.3192173e-06 2.1958783e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[4.4478329e-06 1.0477798e-04 9.8908585e-01 4.3154797e-03 3.9929877e-05\n",
            "  7.1278791e-04 3.5107511e-03 1.6226080e-03 1.3409962e-06 6.0206960e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[3.4073702e-09 9.9964797e-01 2.0558198e-05 1.4468643e-08 4.6193982e-08\n",
            "  7.9352429e-07 2.0371974e-08 3.6728481e-05 2.2920210e-08 2.9389103e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Next \n",
            "[[2.4670094e-02 1.6727603e-06 7.4601718e-05 6.9019072e-05 7.8171504e-01\n",
            "  5.4927892e-04 9.1437902e-04 7.8423203e-05 1.9069576e-01 1.2317470e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Hello \n",
            "[[1.3455066e-03 4.1650257e-08 9.7399825e-06 2.2110480e-04 3.7317935e-01\n",
            "  6.1302278e-05 2.3216173e-02 1.3100337e-04 6.0181469e-01 2.1127151e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[2.5500123e-07 3.5809740e-07 5.4244121e-04 9.9937052e-01 4.0755240e-06\n",
            "  2.2345994e-05 1.2807883e-05 7.2319176e-07 4.6458375e-05 6.1702257e-09]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[9.9746073e-03 5.0223872e-07 8.6105807e-05 2.4746699e-04 3.4596869e-03\n",
            "  1.5149305e-03 9.8112983e-01 3.4228418e-04 3.2166264e-03 2.7911146e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[2.2505219e-06 6.4012101e-03 2.5081930e-03 1.2596672e-06 1.6588044e-04\n",
            "  1.6353905e-03 8.2274877e-05 2.0431285e-01 1.1313594e-04 7.8477752e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[4.5734187e-06 2.0516772e-08 8.5993030e-08 1.5390317e-06 1.7222126e-03\n",
            "  5.4016749e-05 8.8636938e-05 8.4704530e-05 9.9804246e-01 1.6650234e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.5460844e-05 3.1210834e-03 1.2995407e-03 4.6995287e-06 1.8322075e-03\n",
            "  1.3522052e-02 5.0210342e-04 8.7123865e-01 2.7281309e-03 1.0573609e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Stop \n",
            "[[3.7844213e-06 4.9140889e-02 2.2434897e-03 1.5142818e-04 5.4478442e-05\n",
            "  6.8993606e-02 5.7878264e-04 8.4515101e-01 2.8483340e-04 3.3397701e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[8.3866864e-01 1.4222164e-04 8.6670386e-04 1.4305307e-01 1.3803435e-02\n",
            "  2.4899088e-03 2.9749109e-04 4.4920134e-06 6.5939786e-04 1.4518939e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Connection \n",
            "[[9.3487928e-05 5.9644696e-03 9.7616845e-01 7.8626964e-03 3.9665581e-05\n",
            "  9.5010567e-03 9.3993340e-06 4.4450530e-06 1.8454954e-05 3.3784026e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[8.5785771e-08 9.9931276e-01 7.4859086e-06 7.6284203e-07 3.7443789e-07\n",
            "  3.2786658e-05 4.2508225e-07 6.2021369e-04 9.5880823e-06 1.5558689e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[6.6257998e-02 3.3672321e-05 1.7024925e-03 7.9408419e-05 9.2205656e-01\n",
            "  2.0944810e-04 3.0857159e-04 1.5427726e-05 2.3388295e-04 9.1025373e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Navigation \n",
            "[[1.33611306e-04 2.39784331e-05 5.55670960e-03 9.94039655e-01\n",
            "  1.06438965e-05 1.98859212e-04 2.94950169e-05 1.02928675e-06\n",
            "  5.82967141e-06 9.84556223e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[3.41350278e-05 1.12213114e-04 1.38387884e-04 2.41771117e-02\n",
            "  1.39238231e-03 2.18440950e-01 2.21704468e-04 3.38590500e-04\n",
            "  7.55139291e-01 5.18200568e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Web \n",
            "[[1.8595146e-06 8.9125164e-02 8.1495545e-04 2.6653364e-08 6.2826466e-06\n",
            "  9.9546733e-06 9.1286131e-07 1.0580120e-04 1.3455282e-07 9.0993488e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[3.70382564e-04 5.12640085e-03 1.17785879e-03 6.59222901e-02\n",
            "  1.04789004e-04 7.20648229e-01 5.31841367e-02 1.34813726e-01\n",
            "  1.85375232e-02 1.14544346e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[2.6796235e-07 2.1470860e-06 2.5011784e-07 1.1720110e-04 1.2313620e-05\n",
            "  9.5121704e-06 6.3863313e-03 9.2874861e-01 6.4722903e-02 4.3869755e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[3.2484760e-07 2.0001174e-08 2.7607648e-06 2.2630500e-04 2.7014682e-06\n",
            "  2.0638422e-06 9.9523085e-01 4.5254999e-03 9.2350792e-06 1.2298152e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Begin is Begin \n",
            "[[9.9801922e-01 8.3007512e-10 4.1692397e-07 2.1474962e-05 1.9152658e-03\n",
            "  5.0005258e-07 4.0809602e-05 3.3674763e-08 2.8138368e-07 1.9474053e-06]]\n",
            "\n",
            "\n",
            "The predicted word for Choose is Choose \n",
            "[[1.1715813e-06 7.6017809e-01 1.0649648e-05 1.1318860e-05 2.4626124e-06\n",
            "  9.4986922e-04 1.1796159e-05 2.3864174e-01 4.4332162e-05 1.4851618e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Connection is Web \n",
            "[[1.9314485e-03 1.5609777e-03 3.9617922e-03 1.1627680e-04 2.1170634e-03\n",
            "  2.5787361e-03 1.5113421e-02 5.0381683e-02 1.7279797e-04 9.2206579e-01]]\n",
            "\n",
            "\n",
            "The predicted word for Next is Next \n",
            "[[1.6858064e-02 3.2939144e-07 2.7233325e-06 3.1750809e-02 9.5024425e-01\n",
            "  1.7461345e-05 1.9674368e-04 1.4792163e-06 9.2799234e-04 2.1059770e-07]]\n",
            "\n",
            "\n",
            "The predicted word for Navigation is Begin \n",
            "[[8.8233262e-01 2.6807218e-05 4.1172527e-05 8.1581712e-02 7.5076451e-03\n",
            "  1.7407488e-02 6.1646984e-03 7.6053658e-04 4.0712277e-03 1.0620918e-04]]\n",
            "\n",
            "\n",
            "The predicted word for Hello is Hello \n",
            "[[1.7574946e-07 8.2705673e-09 7.9282574e-11 1.6089824e-07 9.8999462e-06\n",
            "  2.3499617e-04 3.8285625e-06 7.0914568e-05 9.9968004e-01 3.0646877e-08]]\n",
            "\n",
            "\n",
            "The predicted word for Stop is Stop \n",
            "[[1.7666718e-05 1.2743490e-05 2.9033270e-06 2.0510684e-05 1.4640652e-05\n",
            "  6.8373937e-04 2.6327390e-02 9.7035563e-01 1.0168885e-03 1.5479052e-03]]\n",
            "\n",
            "\n",
            "The predicted word for Web is Stop \n",
            "[[3.8190956e-05 8.8902554e-05 7.1261020e-05 4.1510821e-06 5.5976129e-06\n",
            "  5.3651826e-03 4.7383551e-03 8.9182961e-01 2.7458795e-05 9.7831436e-02]]\n",
            "\n",
            "\n",
            "The predicted word for Previous is Previous \n",
            "[[2.74144459e-05 3.07180977e-04 7.93542014e-08 1.46672144e-04\n",
            "  1.07087326e-04 7.65661061e-01 1.42967387e-04 6.73791021e-02\n",
            "  1.66216865e-01 1.15277153e-05]]\n",
            "\n",
            "\n",
            "The predicted word for Start is Start \n",
            "[[5.1357709e-03 5.6461460e-07 2.0586367e-05 3.5723643e-03 1.0696294e-05\n",
            "  8.9157764e-03 9.6600217e-01 1.6292699e-02 2.8273420e-05 2.1150223e-05]]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh01ntTrU9fL"
      },
      "source": [
        "# Graphs\n",
        "\n",
        "---\n",
        "\n",
        "Accuracy and loss graphs for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "R3GL8giqlJCa",
        "outputId": "9ecd30a6-37af-4f7e-a241-e8ff5a862589"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_uruY4oJRf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}